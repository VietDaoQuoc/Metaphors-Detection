{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMyrj__qfTBb",
        "outputId": "99a319ca-b85a-4b38-e3b4-d59780443664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prep for mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m pip install opik"
      ],
      "metadata": {
        "id": "nafU-r2tT24n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNd4wW51yzYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e989dbde-6ada-4a89-8fed-62ec2a465019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.26.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Collecting Levenshtein==0.26.0 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.0->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading python_Levenshtein-0.26.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.26.0 python-Levenshtein-0.26.0 rapidfuzz-3.10.0\n",
            "Collecting peft\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: peft\n",
            "Successfully installed peft-0.13.2\n"
          ]
        }
      ],
      "source": [
        "#!python -m pip install wandb -Uq\n",
        "#!python -m pip install ray[tune]\n",
        "# !python -m pip install sigopt\n",
        "# !python -m pip install optuna\n",
        "!python -m pip install nltk python-Levenshtein\n",
        "# !python -m pip install rouge-score\n",
        "!python -m pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet_ml"
      ],
      "metadata": {
        "id": "UvOHA5A0WFNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d1651a-4770-460c-baae-53ebd8bb698c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.47.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
            "Collecting requests-toolbelt>=0.8.0 (from comet_ml)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.32.3)\n",
            "Collecting semantic-version>=2.8.0 (from comet_ml)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting sentry-sdk>=1.1.0 (from comet_ml)\n",
            "  Downloading sentry_sdk-2.17.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting simplejson (from comet_ml)\n",
            "  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.2.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n",
            "Collecting wurlitzer>=1.0.2 (from comet_ml)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.9.2)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.9.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Downloading comet_ml-3.47.0-py3-none-any.whl (694 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.9/694.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dulwich-0.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (968 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m968.1/968.1 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading sentry_sdk-2.17.0-py2.py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.5/314.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: configobj\n",
            "  Building wheel for configobj (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.9-py2.py3-none-any.whl size=35615 sha256=70346c57fe63c750af00c737432b3cd609189c1d84a071d939a802500d40b622\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6c/03/6c5e3cf1a6e4b9e2fc5c4409be4abc5a8268bd9c878739cb32\n",
            "Successfully built configobj\n",
            "Installing collected packages: everett, wurlitzer, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, requests-toolbelt, comet_ml\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.2.0\n",
            "    Uninstalling python-box-7.2.0:\n",
            "      Successfully uninstalled python-box-7.2.0\n",
            "Successfully installed comet_ml-3.47.0 configobj-5.0.9 dulwich-0.22.3 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-2.17.0 simplejson-3.19.3 wurlitzer-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHR3KRT_fcQ0"
      },
      "outputs": [],
      "source": [
        "import comet_ml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import time\n",
        "import logging\n",
        "import numpy as np\n",
        "#import wandb\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import Levenshtein as lev\n",
        "import nltk\n",
        "#from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "#from rouge_score import rouge_scorer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers.models.gpt2.modeling_gpt2 import GPT2Attention\n",
        "from transformers import GPT2Config,  AutoModelForSeq2SeqLM\n",
        "from peft import get_peft_model, IA3Config, TaskType\n",
        "from transformers import TrainerCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGIYACe70tlM"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"WANDB_API_KEY\"] = \"a5d8e3b6d2ef7d55f930ab72670aaa64e1a4198d\"\n",
        "\n",
        "# wandb.login() #enter this token: a5d8e3b6d2ef7d55f930ab72670aaa64e1a4198d\n",
        "# #wandb.init(project=\"huggingface\", entity=\"teamproject464-universit-t-des-saarlandes-saarland-unive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import opik\n",
        "# #kPnaiIq69hBXz7vVAWlDTtRed\n",
        "# opik.configure(use_local=False)"
      ],
      "metadata": {
        "id": "Ewkbc9BtT-5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "comet_ml.login(api_key='kPnaiIq69hBXz7vVAWlDTtRed', project_name='metaphor_detection', workspace='nadias')\n",
        "experiment = comet_ml.Experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPjittT3Vv-u",
        "outputId": "b4696030-450a-474a-a61a-deeb22b8a32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /content/drive/MyDrive/.comet.config (set COMET_CONFIG to change where it is saved).\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/nadias/metaphor-detection/b68bf9385b1c466884cc787bd7e0a13d\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyE3dBXyfiHK",
        "outputId": "df646712-8339-4ab5-a2fa-860598f16895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " annotation_met_new_version.csv   eng_lit_mihan.csv\t      gpt-small-fr-finetuned\n",
            " annotation_nonmet.csv\t\t  eng_met_mihan.csv\t      gpt-small-frfr-finetuned\n",
            "'Colab Notebooks'\t\t  french_gpt_training.ipynb   lit_met.txt\n",
            "'Copy of gpt_training.ipynb'\t  german_gpt_training.ipynb   results\n",
            " df_met_final.txt\t\t  gpt-finetuned\n",
            " eng_all_viet.csv\t\t  gpt-small-eng-finetuned\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "glznVSSQflm0",
        "outputId": "2fd9760e-3f3c-48ea-bd76-50c259534135"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Input  \\\n",
              "0    Des dispositions obligent les établissements f...   \n",
              "1    Nous allons devoir trouver une solution à ce p...   \n",
              "2    Je peux dire également que les Présidences fra...   \n",
              "3    Pourquoi isoler le fondamentalisme religieux e...   \n",
              "4    Je voudrais expliquer à Mme Izquierdo qu' il v...   \n",
              "..                                                 ...   \n",
              "448  Monsieur le Président , la confiance des citoy...   \n",
              "449  Je me demande si ceux qui ont multiplié leurs ...   \n",
              "450  Les drogues cultivées et produites en Afghanis...   \n",
              "451  Le rapport soulève néanmoins des questions imp...   \n",
              "452  La mission qu' Eurostat prévoit d' envoyer en ...   \n",
              "\n",
              "                                           Output  \n",
              "0                                                  \n",
              "1                                                  \n",
              "2                                                  \n",
              "3                                                  \n",
              "4                                                  \n",
              "..                                            ...  \n",
              "448  lunion européenne trouver réponse à problème  \n",
              "449                   eux multiplier intervention  \n",
              "450                       drogue aboutir dans rue  \n",
              "451                    prendre en compte question  \n",
              "452                   mission porter sur question  \n",
              "\n",
              "[453 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caf44e1d-ec86-4209-85ea-58f6d5d1983a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Des dispositions obligent les établissements f...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nous allons devoir trouver une solution à ce p...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Je peux dire également que les Présidences fra...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pourquoi isoler le fondamentalisme religieux e...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Je voudrais expliquer à Mme Izquierdo qu' il v...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>Monsieur le Président , la confiance des citoy...</td>\n",
              "      <td>lunion européenne trouver réponse à problème</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>Je me demande si ceux qui ont multiplié leurs ...</td>\n",
              "      <td>eux multiplier intervention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>Les drogues cultivées et produites en Afghanis...</td>\n",
              "      <td>drogue aboutir dans rue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>Le rapport soulève néanmoins des questions imp...</td>\n",
              "      <td>prendre en compte question</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>La mission qu' Eurostat prévoit d' envoyer en ...</td>\n",
              "      <td>mission porter sur question</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>453 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caf44e1d-ec86-4209-85ea-58f6d5d1983a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-caf44e1d-ec86-4209-85ea-58f6d5d1983a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-caf44e1d-ec86-4209-85ea-58f6d5d1983a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a953cee-b652-4aac-b53a-7f409cef81b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a953cee-b652-4aac-b53a-7f409cef81b1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a953cee-b652-4aac-b53a-7f409cef81b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_20133891-b622-4935-9e0c-2cb8d9535829\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('fr_df_all')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_20133891-b622-4935-9e0c-2cb8d9535829 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('fr_df_all');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "fr_df_all",
              "summary": "{\n  \"name\": \"fr_df_all\",\n  \"rows\": 453,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 453,\n        \"samples\": [\n          \"Il est tout aussi clair que l'Europe n'a pas les ressources pour une identit\\u00e9 europ\\u00e9enne de d\\u00e9fense: nous ne pouvons monter une campagne sans le soutien des Am\\u00e9ricains et de l'OTAN.\",\n          \"Cela signifie que nous ne disposons pas seulement de la perspective de ce sommet du Caire , mais aussi d' une base bien \\u00e9tablie pour continuer , \\u00e9largir et am\\u00e9liorer nos activit\\u00e9s quotidiennes .\",\n          \"Bien que j'\\u00e9prouve une certaine affinit\\u00e9 philosophique avec le s\\u00e9nateur Hollings et ses coll\\u00e8gues, qui consid\\u00e8rent que les entreprises publiques d\\u00e9tiennent des avantages cach\\u00e9s, parfois explicites, par rapport \\u00e0 leurs concurrentes priv\\u00e9es, la mani\\u00e8re dont le Congr\\u00e8s am\\u00e9ricain tente de r\\u00e9gler la situation est contraire tant \\u00e0 l'esprit qu'\\u00e0 la lettre des engagements multilat\\u00e9raux des \\u00c9tats-Unis.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 173,\n        \"samples\": [\n          \"amendement concerner question\",\n          \"programme lutter contre ph\\u00e9nom\\u00e8ne\",\n          \"le Premier ministre trouver terrain dentente\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "# Preprocessing french data\n",
        "\n",
        "def clean_output(text):\n",
        "    # Remove commas, parentheses, and square brackets\n",
        "    return re.sub(r'[\\(\\)\\[\\]\\']', '', text)\n",
        "\n",
        "def clean_output_special(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "    return re.sub(r'[\\[\\]\\']' , '', text)\n",
        "\n",
        "df_literal = pd.read_csv('/content/drive/MyDrive/lit_met.txt', sep='\\t')\n",
        "df_met = pd.read_csv('/content/drive/MyDrive/df_met_final.txt', sep='\\t')\n",
        "\n",
        "df_literal = df_literal.rename(columns={'Sentence': 'Input'})\n",
        "df_met = df_met.rename(columns={'Sentence': 'Input'})\n",
        "\n",
        "# clean output\n",
        "df_literal['Output'] = df_literal['Output'].apply(clean_output_special)\n",
        "df_met['Output'] = df_met['Output'].apply(clean_output_special)\n",
        "\n",
        "df_literal['Input'] = df_literal['Input'].str.strip()\n",
        "df_literal['Output'] = df_literal['Output'].str.strip()\n",
        "df_literal = df_literal.dropna(subset=['Input', 'Output'])\n",
        "\n",
        "df_met['Input'] = df_met['Input'].str.strip()\n",
        "df_met['Output'] = df_met['Output'].str.strip()\n",
        "df_met = df_met.dropna(subset=['Input', 'Output'])\n",
        "\n",
        "fr_df_all = pd.concat([df_literal, df_met], ignore_index=True)\n",
        "fr_df_all = fr_df_all.dropna()\n",
        "\n",
        "# Put a placeholder for all the instances where there is no metaphor, as NAN cannot be procesed later\n",
        "fr_df_all['Output'] = fr_df_all['Output'].replace(\"\", \" \")\n",
        "# pad the ouptuts and ensure there is always a triple\n",
        "def ensure_triple(data):\n",
        "    result = []\n",
        "    for item in data:\n",
        "        #item = item.replace(\",\", \"|\")\n",
        "        item_list = [x.strip() for x in item.split(\",\")]\n",
        "        # If the item is a tuple or list, convert it to a list and check its length\n",
        "        if len(item_list) < 3:\n",
        "            item_list.append('')\n",
        "            # If it has less than 3 elements, add 'nothing' to fill the missing slots\n",
        "            while len(item_list) < 3:\n",
        "                item_list.append(\"\")\n",
        "\n",
        "        item =\" \".join(item_list)\n",
        "        result.append(item)\n",
        "    return result\n",
        "\n",
        "fr_df_all['Output'] = ensure_triple(fr_df_all['Output'])\n",
        "fr_df_all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing english data\n",
        "\n",
        "def clean_output(text):\n",
        "    # Remove commas, parentheses, and square brackets\n",
        "    return re.sub(r'[\\(\\)\\[\\]\\']', '', text)\n",
        "\n",
        "def clean_output_special(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "    return re.sub(r'[\\[\\]\\']' , '', text)\n",
        "df_literal = pd.read_csv('/content/drive/MyDrive/eng_lit_mihan.csv', delimiter=';', encoding='ISO-8859-1')\n",
        "\n",
        "\n",
        "df_literal['Output'] = df_literal['Output'].apply(clean_output_special)\n",
        "df_literal['Input'] = df_literal['Input'].str.strip()\n",
        "df_literal['Output'] = df_literal['Output'].str.strip()\n",
        "df_literal = df_literal.dropna(subset=['Input', 'Output'])\n",
        "# size 350\n",
        "# for index, row in df_cleaned.iterrows():\n",
        "#     print(index)\n",
        "#     print(row['Input'])\n",
        "#     print(row['Output'])\n",
        "\n",
        "\n",
        "# Output (Subject, Verb, Object For Active voices) and (Object, Verb, Subjet For Passive Voices)\n",
        "df_met = pd.read_csv('/content/drive/MyDrive/eng_met_mihan.csv', delimiter=';', encoding='UTF-8')\n",
        "\n",
        "df_met = df_met.rename(columns={'Output (Subject, Verb, Object For Active voices) and (Object, Verb, Subjet For Passive Voices)': 'Output'})\n",
        "df_met['Output'] = df_met['Output'].apply(clean_output)\n",
        "df_met['Input'] = df_met['Input'].str.strip()\n",
        "df_met['Output'] = df_met['Output'].str.strip()\n",
        "df_met = df_met.drop(columns=['Verb'])\n",
        "df_met = df_met.dropna(subset=['Input', 'Output'])\n",
        "\n",
        "# size 350\n",
        "# Now Viet's\n",
        "eng_all_viet = pd.read_csv('/content/drive/MyDrive/eng_all_viet.csv',delimiter=';', encoding='UTF-8' )\n",
        "eng_all_viet = eng_all_viet.rename(columns={'Tuple SVO': 'Output'})\n",
        "eng_all_viet = eng_all_viet.rename(columns={'Sentence': 'Input'})\n",
        "\n",
        "# swap the columns to match the other dataset\n",
        "cols = list(eng_all_viet.columns)\n",
        "\n",
        "# Swap the first two elements\n",
        "#cols[0], cols[1] = cols[1], cols[0]\n",
        "\n",
        "# Reorder the DataFrame using the new column order\n",
        "# why 399 ? 235 literal and 164 metaphores ? sure\n",
        "#eng_all_viet = eng_all_viet[cols]\n",
        "\n",
        "eng_all_viet['Output'] = eng_all_viet['Output'].apply(clean_output)\n",
        "empty_count = 0\n",
        "met_count = 0\n",
        "\n",
        "for index, row in eng_all_viet.iterrows():\n",
        "    if row['Output'] == '':\n",
        "        empty_count += 1\n",
        "    else:\n",
        "        met_count += 1\n",
        "\n",
        "\n",
        "eng_df_all = pd.concat([eng_all_viet, df_met, df_literal], ignore_index=True)\n",
        "\n",
        "\n",
        "eng_df_all = eng_df_all.dropna()\n",
        "\n",
        "# Put a placeholder for all the instances where there is no metaphor, as NAN cannot be procesed later\n",
        "eng_df_all['Output'] = eng_df_all['Output'].replace(\"\", \"\")\n",
        "# pad the ouptuts and ensure there is always a triple\n",
        "def ensure_triple(data):\n",
        "    result = []\n",
        "    for item in data:\n",
        "        #item = item.replace(\",\", \"|\")\n",
        "        item_list = [x.strip() for x in item.split(\",\")]\n",
        "        # If the item is a tuple or list, convert it to a list and check its length\n",
        "        if len(item_list) < 3:\n",
        "            item_list.append('')\n",
        "            # If it has less than 3 elements, add 'nothing' to fill the missing slots\n",
        "            while len(item_list) < 3:\n",
        "                item_list.append(\"\")\n",
        "\n",
        "        item =\" \".join(item_list)\n",
        "        result.append(item)\n",
        "    return result\n",
        "\n",
        "eng_df_all['Output'] = ensure_triple(eng_df_all['Output'])\n",
        "\n",
        "eng_df_all.iloc[707]['Input']  # 415, 3, 700"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1o3euvH1yf3d",
        "outputId": "a242da93-549f-466e-b03d-be7e4fc639a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'But he grasped the potential of putting the two together.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing german data\n",
        "\n",
        "def clean_output(text):\n",
        "    # Remove commas, parentheses, and square brackets\n",
        "    return re.sub(r'[\\(\\)\\[\\]\\']', '', text)\n",
        "\n",
        "def clean_output_special(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "    return re.sub(r'[\\[\\]\\']' , '', text)\n",
        "\n",
        "df_literal = pd.read_csv('/content/drive/MyDrive/annotation_nonmet.csv', delimiter=';', header=None)\n",
        "df_met = pd.read_csv('/content/drive/MyDrive/annotation_met_new_version.csv', delimiter=';', header=None)\n",
        "\n",
        "df_literal.columns = ['Input', 'Output']\n",
        "df_met.columns = ['Input', 'Output']\n",
        "df_literal\n",
        "\n",
        "# clean output\n",
        "\n",
        "\n",
        "df_literal['Input'] = df_literal['Input'].str.strip()\n",
        "df_literal['Output'] = df_literal['Output'].str.strip()\n",
        "df_literal = df_literal.dropna(subset=['Input', 'Output'])\n",
        "\n",
        "df_met['Input'] = df_met['Input'].str.strip()\n",
        "df_met['Output'] = df_met['Output'].str.strip()\n",
        "df_met = df_met.dropna(subset=['Input', 'Output'])\n",
        "\n",
        "\n",
        "df_literal['Output'] = df_literal['Output'].apply(clean_output)\n",
        "df_met['Output'] = df_met['Output'].apply(clean_output)\n",
        "#reset indexes\n",
        "\n",
        "df_met = df_met.reset_index(drop=True)\n",
        "df_literal = df_literal.reset_index(drop=True)\n",
        "\n",
        "ger_df_all = pd.concat([df_literal, df_met], ignore_index=True)\n",
        "ger_df_all = ger_df_all.dropna()\n",
        "\n",
        "# Put a placeholder for all the instances where there is no metaphor, as NAN cannot be procesed later\n",
        "\n",
        "ger_df_all['Output'] = ger_df_all['Output'].replace(\"\", \" \")\n",
        "# pad the ouptuts and ensure there is always a triple\n",
        "def ensure_triple(data):\n",
        "    result = []\n",
        "    for item in data:\n",
        "        #item = item.replace(\",\", \"|\")\n",
        "        item_list = [x.strip() for x in item.split(\",\")]\n",
        "        # If the item is a tuple or list, convert it to a list and check its length\n",
        "        if len(item_list) < 3:\n",
        "            item_list.append('')\n",
        "            # If it has less than 3 elements, add 'nothing' to fill the missing slots\n",
        "            while len(item_list) < 3:\n",
        "                item_list.append(\"\")\n",
        "\n",
        "        item =\" \".join(item_list)\n",
        "        result.append(item)\n",
        "    return result\n",
        "\n",
        "ger_df_all['Output'] = ensure_triple(ger_df_all['Output'])\n",
        "ger_df_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "BYiMhWWEJoRX",
        "outputId": "c0b3473a-d49f-41d5-d1ca-24363798639e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-6a4c57aed967>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_literal['Output'] = df_literal['Output'].apply(clean_output)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Input  \\\n",
              "0    Die von der Stiftung Preußische Seehandlung ve...   \n",
              "1    Die von der Budgetgemeindeversammlung beschlos...   \n",
              "2    Die werden sich an Sie erinnern, auch wenn Sie...   \n",
              "3    Doch dann habe man den Sonderausschuss zu Beng...   \n",
              "4    Doch dann wird Melanie mit Bens Vergangenheit ...   \n",
              "..                                                 ...   \n",
              "341  Von rechten bis konservativen Politikern werde...   \n",
              "342  Die Attentäter von Paris haben auf der Flucht ...   \n",
              "343  Um dieses Ziel zu erreichen, ist Einsatz gefra...   \n",
              "344  Auch wenn man schöne Zeiten wie den Aufstieg o...   \n",
              "345  Auch in der Einwanderungs- und Außenpolitik st...   \n",
              "\n",
              "                               Output  \n",
              "0                                      \n",
              "1                                      \n",
              "2                                      \n",
              "3                                      \n",
              "4                                      \n",
              "..                                ...  \n",
              "341                    Angst schüren   \n",
              "342                 auf Spur bringen   \n",
              "343                  fahren an Limit   \n",
              "344                  Lücke schließen   \n",
              "345  Zeichen stehen auf Konfrontation  \n",
              "\n",
              "[346 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be49d997-3152-4862-921e-cacf88f24168\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Die von der Stiftung Preußische Seehandlung ve...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Die von der Budgetgemeindeversammlung beschlos...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Die werden sich an Sie erinnern, auch wenn Sie...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Doch dann habe man den Sonderausschuss zu Beng...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doch dann wird Melanie mit Bens Vergangenheit ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>Von rechten bis konservativen Politikern werde...</td>\n",
              "      <td>Angst schüren</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>Die Attentäter von Paris haben auf der Flucht ...</td>\n",
              "      <td>auf Spur bringen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>Um dieses Ziel zu erreichen, ist Einsatz gefra...</td>\n",
              "      <td>fahren an Limit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Auch wenn man schöne Zeiten wie den Aufstieg o...</td>\n",
              "      <td>Lücke schließen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>Auch in der Einwanderungs- und Außenpolitik st...</td>\n",
              "      <td>Zeichen stehen auf Konfrontation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>346 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be49d997-3152-4862-921e-cacf88f24168')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be49d997-3152-4862-921e-cacf88f24168 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be49d997-3152-4862-921e-cacf88f24168');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3643f750-b024-42d8-b62b-97e35cfd0468\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3643f750-b024-42d8-b62b-97e35cfd0468')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3643f750-b024-42d8-b62b-97e35cfd0468 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_41b34370-47fd-4644-893e-d40ed6894c41\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ger_df_all')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_41b34370-47fd-4644-893e-d40ed6894c41 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ger_df_all');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ger_df_all",
              "summary": "{\n  \"name\": \"ger_df_all\",\n  \"rows\": 346,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 346,\n        \"samples\": [\n          \"Neu k\\u00f6nnen der Sportpass online verl\\u00e4ngert und Einzeleintritte zu Hause ausgedruckt werden.\",\n          \"Das letzte Mal, dass er ein Grand-Slam-Finale au\\u00dferhalb von London erreichte, liegt mehr als vier Jahre zur\\u00fcck.\",\n          \"Die Fernsehserie wird sich um Lucifer drehen, der ungl\\u00fccklich als Herrscher \\u00fcber die H\\u00f6lle der Langeweile \\u00fcberdr\\u00fcssig ist.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"Weg einschlagen Verb\\u00fcndeter unter Druck setzen\",\n          \"dahinschmelzen  \",\n          \"Weichen stellen \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeds8sQjysZA"
      },
      "outputs": [],
      "source": [
        "# Optimizersss\n",
        "#1. Optuna\n",
        "\n",
        "def optuna_hp_space(trial):\n",
        "\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64, 128]),\n",
        "    }\n",
        "\n",
        "#2. SigOpt\n",
        "\n",
        "def sigopt_hp_space(trial):\n",
        "\n",
        "    return [\n",
        "        {\"bounds\": {\"min\": 1e-6, \"max\": 1e-4}, \"name\": \"learning_rate\", \"type\": \"double\"},\n",
        "        {\n",
        "            \"categorical_values\": [\"16\", \"32\", \"64\", \"128\"],\n",
        "            \"name\": \"per_device_train_batch_size\",\n",
        "            \"type\": \"categorical\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "#3. raytune\n",
        "\n",
        "def ray_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": tune.loguniform(1e-6, 1e-4),\n",
        "        \"per_device_train_batch_size\": tune.choice([16, 32, 64, 128]),\n",
        "    }\n",
        "\n",
        "#4.Wandb\n",
        "def wandb_hp_space(trial):\n",
        "    return {\n",
        "        \"method\": \"random\",\n",
        "        \"metric\": {\"name\": \"objective\", \"goal\": \"minimize\"},\n",
        "        \"parameters\": {\n",
        "            \"learning_rate\": {\"distribution\": \"uniform\", \"min\": 1e-6, \"max\": 1e-4},\n",
        "            \"per_device_train_batch_size\": {\"values\": [16, 32, 64, 128]},\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ysEfG2j53Eg"
      },
      "outputs": [],
      "source": [
        "# # include new metrics in class TRAINER\n",
        "\n",
        "# class CustomTrainer(Trainer):\n",
        "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
        "#         # Get model predictions\n",
        "#         outputs = model(**inputs)\n",
        "#         logits = outputs.get('logits')\n",
        "#         labels = inputs.get('labels')\n",
        "\n",
        "#         # Convert logits to predicted tokens\n",
        "#         predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "#         # Compute standard cross-entropy loss (you can keep this for token-level guidance)\n",
        "#         loss_fct = torch.nn.CrossEntropyLoss()\n",
        "#         loss = loss_fct(logits.view(-1, self.model.config.vocab_size), labels.view(-1))\n",
        "\n",
        "#         # Convert predictions and labels to text (for custom metrics)\n",
        "#         pred_texts = [tokenizer.decode(pred, skip_special_tokens=True).strip() for pred in predictions]\n",
        "#         label_texts = [tokenizer.decode(label, skip_special_tokens=True).strip() for label in labels]\n",
        "\n",
        "#         # 1. Cosine Similarity Metric\n",
        "#         cos_loss = 0.0\n",
        "#         for pred_text, label_text in zip(pred_texts, label_texts):\n",
        "#             if pred_text and label_text: # check that pred and label are non-empty\n",
        "#               pred_vec = tokenizer.encode(pred_text, return_tensors='pt')\n",
        "#               label_vec = tokenizer.encode(label_text, return_tensors='pt')\n",
        "#               if pred_vec.shape[1] > 0 and label_vec.shape[1] > 0: # check that arrays are non-empty\n",
        "#                 cos_sim = cosine_similarity(pred_vec.detach().numpy(), label_vec.detach().numpy())\n",
        "#                 cos_loss += 1 - cos_sim.mean()  # Convert similarity to distance\n",
        "#               else:\n",
        "#                 # Handle cases where vectors are empty, possibly by assigning a default loss\n",
        "#                 cos_loss += 1 # Assign highest possible loss (1) if vectors are empty\n",
        "#             else:\n",
        "#               cos_loss += 1 #Assign highest possible loss if predictions or labels are empty\n",
        "\n",
        "#         # Normalize the cosine loss by batch size\n",
        "#         cos_loss /= len(pred_texts)\n",
        "\n",
        "#         # 2. Levenshtein Distance Metric\n",
        "#         lev_loss = 0.0\n",
        "#         for pred_text, label_text in zip(pred_texts, label_texts):\n",
        "#             lev_distance = Levenshtein.distance(pred_text, label_text)\n",
        "#             max_len = max(len(pred_text), len(label_text))\n",
        "#             lev_loss += lev_distance / max_len  # Normalize Levenshtein distance by the max length\n",
        "\n",
        "#         # Normalize Levenshtein loss by batch size\n",
        "#         lev_loss /= len(pred_texts)\n",
        "\n",
        "#         # Combine the original cross-entropy loss with custom metrics\n",
        "#         combined_loss = loss + cos_loss + lev_loss\n",
        "\n",
        "#         return (combined_loss, outputs) if return_outputs else combined_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncxnIu6AzCn8"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPMgfE3AigIm"
      },
      "outputs": [],
      "source": [
        "def levenshtein_metric(predictions, references):\n",
        "    distances = []\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        pred_text = tokenizer.decode(pred, skip_special_tokens=True)\n",
        "        ref_text = tokenizer.decode(ref, skip_special_tokens=True)\n",
        "        # Compute the normalized Levenshtein distance\n",
        "        distance = lev.distance(pred_text, ref_text) / max(len(pred_text), len(ref_text))\n",
        "        distances.append(1 - distance)  # Invert it to represent similarity\n",
        "    return np.mean(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWjljYfBieJg"
      },
      "outputs": [],
      "source": [
        "def token_level_metrics(predictions, references):\n",
        "    precision_list, recall_list, f1_list = [], [], []\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        pred_ids = pred.flatten()  # Flatten the tensor if needed\n",
        "        ref_ids = ref.flatten()\n",
        "\n",
        "        # Ignore padding tokens (or other special tokens if defined)\n",
        "        mask = ref_ids != tokenizer.pad_token_id\n",
        "\n",
        "        # Compute precision, recall, f1\n",
        "        precision = precision_score(ref_ids[mask], pred_ids[mask], average='micro')\n",
        "        recall = recall_score(ref_ids[mask], pred_ids[mask], average='micro')\n",
        "        f1 = f1_score(ref_ids[mask], pred_ids[mask], average='micro')\n",
        "\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "    return np.mean(precision_list), np.mean(recall_list), np.mean(f1_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubW_ftuxib7H",
        "outputId": "c809d7dc-e49e-45c3-c789-35b0af00a247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "# def bleu_score_metric(predictions, references):\n",
        "#     bleu_scores = []\n",
        "#     for pred, ref in zip(predictions, references):\n",
        "#         pred_tokens = tokenizer.decode(pred, skip_special_tokens=True).split()\n",
        "#         ref_tokens = tokenizer.decode(ref, skip_special_tokens=True).split()\n",
        "\n",
        "#         # Calculate the BLEU score for each pair of sentences\n",
        "#         bleu_scores.append(sentence_bleu([ref_tokens], pred_tokens))\n",
        "\n",
        "#     return np.mean(bleu_scores)\n",
        "def bleu_score_metric(predictions, references):\n",
        "    bleu_scores = []\n",
        "    smoothing_function = SmoothingFunction().method4  # Apply smoothing to handle missing n-grams\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        pred_tokens = tokenizer.decode(pred, skip_special_tokens=True).split()\n",
        "        ref_tokens = tokenizer.decode(ref, skip_special_tokens=True).split()\n",
        "\n",
        "        # Calculate the BLEU score for each pair of sentences with smoothing\n",
        "        bleu_scores.append(sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothing_function))\n",
        "\n",
        "    return np.mean(bleu_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mCtFZUkrDcD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_rouge(reference, hypothesis):\n",
        "    # Initialize ROUGE scorer\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    scores = scorer.score(reference, hypothesis)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kygRsv9IiZLG"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    levenshtein_sim = levenshtein_metric(predictions, labels)\n",
        "    precision, recall, f1 = token_level_metrics(predictions, labels)\n",
        "    return {\n",
        "        'levenshtein_similarity': levenshtein_sim,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55dkpcU-yxA9"
      },
      "outputs": [],
      "source": [
        "# # Hypertune with IA3\n",
        "# class IA3Layer(nn.Module):\n",
        "#     def __init__(self, hidden_dim):\n",
        "#         super(IA3Layer, self).__init__()\n",
        "#         # Learnable scaling vectors for keys, queries, and values\n",
        "#         self.ia3_key = nn.Parameter(torch.ones(hidden_dim))\n",
        "#         self.ia3_query = nn.Parameter(torch.ones(hidden_dim))\n",
        "#         self.ia3_value = nn.Parameter(torch.ones(hidden_dim))\n",
        "\n",
        "#     def forward(self, query, key, value):\n",
        "#         # Apply input-aware scaling to keys, queries, and values\n",
        "\n",
        "#         print(f\"Query shape before IA3: {query.shape}\", flush=True)\n",
        "#         print(f\"Key shape before IA3: {key.shape}\",  flush=True)\n",
        "#         print(f\"Value shape before IA3: {value.shape}\",  flush=True)\n",
        "\n",
        "#         query = query * self.ia3_query\n",
        "#         key = key * self.ia3_key\n",
        "#         value = value * self.ia3_value\n",
        "\n",
        "#         print(f\"Query shape after IA3: {query.shape}\",  flush=True)\n",
        "#         print(f\"Key shape after IA3: {key.shape}\",  flush=True)\n",
        "#         print(f\"Value shape after IA3: {value.shape}\",  flush=True)\n",
        "#         return query, key, value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M_vt2fxzOpx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# class GPT2AttentionWithIA3(GPT2Attention):\n",
        "#     def __init__(self, config):\n",
        "#         super().__init__(config)\n",
        "#         # Initialize IA3 scaling layers\n",
        "#         self.ia3 = IA3Layer(config.hidden_size)\n",
        "\n",
        "#     def forward(self, hidden_states, layer_past=None, attention_mask=None, head_mask=None, use_cache=False, output_attentions=False):\n",
        "#         # Perform the standard GPT-2 attention mechanism\n",
        "#         print(\"1\",  flush=True)\n",
        "#         query, key, value = self._attn(hidden_states, attention_mask, head_mask, use_cache, output_attentions)\n",
        "#         print(\"2\",  flush=True)\n",
        "#         # Apply IA3 scaling\n",
        "#         query, key, value = self.ia3(query, key, value)\n",
        "#         print(\"3\",  flush=True)\n",
        "#         # Proceed with the rest of the attention mechanism (unchanged)\n",
        "#         return super().forward(hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL10KUtDzRzQ"
      },
      "outputs": [],
      "source": [
        "# class GPT2WithIA3(GPT2LMHeadModel):\n",
        "#     def __init__(self, config):\n",
        "#         super().__init__(config)\n",
        "#         # Replace the attention layers with IA3-enhanced layers\n",
        "#         for layer in self.transformer.h:\n",
        "#             layer.attn = GPT2AttentionWithIA3(config)\n",
        "\n",
        "# # Load the pre-trained GPT-2 model and replace the attention layers\n",
        "# config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "# model = GPT2WithIA3(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMV3drSdfrGk",
        "outputId": "a0fd8df3-dd4c-4de2-ca3c-a37c1deaa43b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50258, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2SdpaAttention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
            ")\n",
            "trainable params: 38,653,440 || all params: 163,094,016 || trainable%: 23.7001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/ia3/model.py:134: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name=\"antoiloui/belgpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "#config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "#model = GPT2WithIA3(config)\n",
        "\n",
        "# Add the padding token to GPT-2's tokenizer (optional, but useful)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# Hook to capture layer activations\n",
        "def get_layer_weights_hook(module, input, output):\n",
        "    # Save the output (weights after decoding) from the layer\n",
        "    module.layer_outputs = output.detach().cpu().numpy()\n",
        "\n",
        "# Attach the hook to a specific layer you want to probe (e.g., the decoder layer)\n",
        "model.lm_head.register_forward_hook(get_layer_weights_hook)\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=32, max_length_out = 32):\n",
        "        self.inputs = df['Input'].tolist()\n",
        "        self.outputs = df['Output'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.max_length_out= max_length_out\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.inputs[idx]\n",
        "        output_text = self.outputs[idx]\n",
        "\n",
        "        tokenized_output = self.tokenizer(output_text, truncation=True, return_tensors='pt', padding='max_length', max_length=self.max_length_out)\n",
        "        tokenized_input = self.tokenizer(input_text, truncation=True, return_tensors='pt', padding='max_length', max_length=self.max_length)\n",
        "        #print(tokenized_input['input_ids'].shape, tokenized_output['input_ids'].shape)\n",
        "\n",
        "        # create Mask for empty and delimiter\n",
        "        empty_token_id = self.tokenizer.convert_tokens_to_ids('<EMPTY>')\n",
        "        output_mask = (output_ids != empty_token_id).long()\n",
        "        # resize the model after introducing special tokens # and |\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "        # Return input_ids and attention_mask for training, no labels\n",
        "\n",
        "        # Input IDs and attention mask\n",
        "        input_ids = tokenized_input['input_ids'].squeeze()  # shape: (max_length)\n",
        "        attention_mask = tokenized_input['attention_mask'].squeeze()  # shape: (max_length)\n",
        "        output_ids = tokenized_output['input_ids'].squeeze()  # shape: (max_length)\n",
        "\n",
        "        # Return input_ids and attention_mask for training, no labels\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': output_ids,\n",
        "            'output_mask': output_mask\n",
        "        }\n",
        "\n",
        "class MaskedTextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=32, max_length_out = 32):\n",
        "        self.inputs = df['Input'].tolist()\n",
        "        self.outputs = df['Output'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.max_length_out= max_length_out\n",
        "        self.stored_input_ids = []  # Store the input IDs here\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.inputs[idx]\n",
        "        output_text = self.outputs[idx]\n",
        "\n",
        "        tokenized_output = self.tokenizer(output_text, truncation=True, return_tensors='pt', padding='max_length', max_length=self.max_length)\n",
        "        tokenized_input = self.tokenizer(input_text, truncation=True, return_tensors='pt', padding='max_length', max_length=self.max_length)\n",
        "        #print(tokenized_input['input_ids'].shape, tokenized_output['input_ids'].shape)\n",
        "        # Input IDs and attention mask\n",
        "        input_ids = tokenized_input['input_ids'].squeeze()  # shape: (max_length)\n",
        "        attention_mask = tokenized_input['attention_mask'].squeeze()  # shape: (max_length)\n",
        "        output_ids = tokenized_output['input_ids'].squeeze()  # shape: (max_length)\n",
        "\n",
        "        # create Mask for empty and delimiter\n",
        "        #hash_token_id = self.tokenizer.convert_tokens_to_ids('#')\n",
        "        #delimiter_token_id = self.tokenizer.convert_tokens_to_ids('|')\n",
        "\n",
        "        #output_mask = (output_ids != hash_token_id).long() & (output_ids != delimiter_token_id).long()\n",
        "        self.stored_input_ids.append(input_ids.tolist())  # Store the input IDs\n",
        "        # Return input_ids and attention_mask for training, no labels\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': output_ids\n",
        "        }\n",
        "\n",
        "class TextDatasetWithPrompts(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=64, max_length_out=64):\n",
        "        self.inputs = df['Input'].tolist()\n",
        "        self.outputs = df['Output'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.max_length_out = max_length_out\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = f\"Input: {self.inputs[idx]}\\nOutput:\"\n",
        "        output_text = self.outputs[idx]\n",
        "\n",
        "        tokenized_input = self.tokenizer(\n",
        "            input_text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt'\n",
        "        )\n",
        "        tokenized_output = self.tokenizer(\n",
        "            output_text, truncation=True, padding='max_length', max_length=self.max_length_out, return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = tokenized_input['input_ids'].squeeze()\n",
        "        attention_mask = tokenized_input['attention_mask'].squeeze()\n",
        "        output_ids = tokenized_output['input_ids'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': output_ids\n",
        "        }\n",
        "\n",
        "# Load data into the custom dataset\n",
        "My_dataset = MaskedTextDataset(df=fr_df_all, tokenizer=tokenizer)\n",
        "# Split into training and test sets\n",
        "split = 0.8\n",
        "train_eval_size = int(split * len(My_dataset))\n",
        "test_size = len(My_dataset) - train_eval_size\n",
        "train_eval_data, test_data = random_split(My_dataset, [train_eval_size, test_size])\n",
        "\n",
        "train_size = int(split * len(train_eval_data))\n",
        "eval_size = len(train_eval_data) - train_size\n",
        "training_data, eval_data = random_split(train_eval_data, [train_size, eval_size])\n",
        "\n",
        "# Define DataLoaders\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "# dataloader_train = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "# dataloader_eval = DataLoader(eval_data, batch_size=batch_size, shuffle=True)\n",
        "# dataloader_test = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "######\n",
        "# masking outside\n",
        "#special_tokens_dict = {'additional_special_tokens': ['#']}\n",
        "#tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "class LogInputIDsCallback(TrainerCallback):\n",
        "    def __init__(self, experiment, tokenizer, My_dataset):\n",
        "        self.experiment = experiment\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dataset = My_dataset\n",
        "    def on_log(self, args, state, control, **kwargs):\n",
        "        step = state.global_step\n",
        "        print(step)\n",
        "        # Get the corresponding input_ids from the dataset\n",
        "        input_ids = self.dataset.stored_input_ids[-step:]\n",
        "        print(input_ids)\n",
        "        if input_ids is not None:\n",
        "              for ids in input_ids:\n",
        "                  tokens = self.tokenizer.convert_ids_to_tokens(ids)\n",
        "                  tokens = self.tokenizer.decode(tokens)\n",
        "                  token_str = \" \".join(tokens)\n",
        "                  print(f\"Logging tokens for step {step}: {token_str}\")\n",
        "\n",
        "                  # Log to Comet\n",
        "                  self.experiment.log_text(f\"Tokens: {token_str}\", metadata={\"step\": step})\n",
        "######\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    logging_steps=50,\n",
        "    output_dir='./results-small',\n",
        "    learning_rate = 5e-4,\n",
        "    weight_decay = 0.01,\n",
        "    gradient_accumulation_steps=3,\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    eval_strategy=\"epoch\",\n",
        "    report_to=\"comet_ml\"  # This enables reporting to Comet\n",
        ")\n",
        "\n",
        "# Model Init for hyperparam optimization\n",
        "\n",
        "\n",
        "# model_args = {\n",
        "#     \"model\": model_name,\n",
        "#     \"from_tf\": False,\n",
        "#     \"config\": AutoConfig.from_pretrained(model_name),\n",
        "#     \"cache_dir\": None, # You can specify a cache directory if needed\n",
        "#     \"revision\": None, # You can specify a model revision if needed\n",
        "#     \"token\": True # Set to True if using an authentication token\n",
        "# }\n",
        "\n",
        "# def model_init(trial):\n",
        "#     model = GPT2LMHeadModel.from_pretrained(\n",
        "#         model_name,\n",
        "#         ignore_mismatched_sizes=True,\n",
        "#         from_tf=bool(\".ckpt\" in model_name),\n",
        "#         config= AutoConfig.from_pretrained(model_name),\n",
        "#         cache_dir=None,\n",
        "#         revision=None,\n",
        "#         token=True,\n",
        "#     )\n",
        "#     model.config.pad_token_id = tokenizer.eos_token_id\n",
        "#     return model\n",
        "\n",
        "#IA3 init config\n",
        "peft_config = IA3Config(\n",
        "    task_type=TaskType.CAUSAL_LM,  # Task type (change if necessary)\n",
        "    target_modules=[\"attn.c_attn\",\"attn.c_proj\", \"mlp.c_proj\",\"mlp.c_fc\"],  # Attention block layers to apply IA3\n",
        "    feedforward_modules=[\"mlp.c_fc\"],  # Apply to feedforward layers\n",
        "    modules_to_save=[\"lm_head\"],  # List of trainable modules to save\n",
        ")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "print(model)\n",
        "# Wrap the model using the PEFT IA3 method\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# Optional: Print trainable parameters\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "#Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=training_data,\n",
        "    eval_dataset=eval_data,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MSv5UNo7h7S"
      },
      "outputs": [],
      "source": [
        "# #Initialize the Trainer with wandb stuff\n",
        "# trainer = Trainer(\n",
        "#     model_init=model_init, # This is for the model init for the hyperparm optim\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=training_data,\n",
        "#     eval_dataset=eval_data\n",
        "# )\n",
        "# trainer = CustomTrainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=training_data,\n",
        "#     eval_dataset=eval_data,\n",
        "#     tokenizer=tokenizer,\n",
        "#     compute_metrics=compute_metrics  # Optionally include custom metrics\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up7oQFXFzAiO"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# ## Get best hyperparams\n",
        "# best_trials = trainer.hyperparameter_search(\n",
        "#     direction=[\"minimize\", \"maximize\"],\n",
        "#     backend=\"optuna\",\n",
        "#     hp_space=optuna_hp_space,\n",
        "#     n_trials=10\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "4CTnXtcTfu4X",
        "outputId": "3ac576f5-4cb8-4509-b81d-59e22aab180e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training starts\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 14:49, Epoch 30/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Levenshtein Similarity</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>15.819966</td>\n",
              "      <td>0.050115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>14.990126</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>13.906813</td>\n",
              "      <td>0.050437</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>13.271584</td>\n",
              "      <td>0.050417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>12.377707</td>\n",
              "      <td>0.050706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>11.804815</td>\n",
              "      <td>0.051631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>11.004110</td>\n",
              "      <td>0.051436</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>10.544038</td>\n",
              "      <td>0.051099</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>9.878005</td>\n",
              "      <td>0.051488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>9.469771</td>\n",
              "      <td>0.051361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.946671</td>\n",
              "      <td>0.051269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.635949</td>\n",
              "      <td>0.051313</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.215587</td>\n",
              "      <td>0.051773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.966801</td>\n",
              "      <td>0.052054</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.648821</td>\n",
              "      <td>0.052590</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.470781</td>\n",
              "      <td>0.052459</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.255972</td>\n",
              "      <td>0.052411</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.147218</td>\n",
              "      <td>0.052827</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.033942</td>\n",
              "      <td>0.053332</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.990225</td>\n",
              "      <td>0.053441</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>9.264100</td>\n",
              "      <td>6.971639</td>\n",
              "      <td>0.053453</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>0.006849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Start finetuning\n",
        "start_time = time.time()\n",
        "print('Training starts')\n",
        "trainer.train()\n",
        "model.save_pretrained(\"/content/drive/MyDrive/gpt-small-frfr-finetuned\")\n",
        "#model.save_weights(\"/content/drive/MyDrive/weights.h5\")\n",
        "print('Training done')\n",
        "end_time = time.time()\n",
        "experiment.end()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t9fToKXdMdlf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0shLcvefwrY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "aaf64904-0825-4749-fb9d-129ed11659a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 911.11 seconds.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 6.971639156341553,\n",
              " 'eval_levenshtein_similarity': 0.05345326354677708,\n",
              " 'eval_precision': 0.00684931506849315,\n",
              " 'eval_recall': 0.00684931506849315,\n",
              " 'eval_f1': 0.00684931506849315,\n",
              " 'eval_runtime': 3.7258,\n",
              " 'eval_samples_per_second': 19.593,\n",
              " 'eval_steps_per_second': 0.537,\n",
              " 'epoch': 30.0}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "fine_tuning_time = end_time - start_time\n",
        "print(f\"Training completed in {fine_tuning_time:.2f} seconds.\")\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLoe0jg1fxQ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6b26ec6f-1380-4aa0-a1cb-9a093132bb42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "predictions, labels, metrics = trainer.predict(test_dataset=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUjAIm-ifz1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cdd4265-5b87-4669-b438-34d229c2ef70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"ée que,, des des,� nous que nous l marché en commun nos énergie � notre efforts �' actionsergie �       \",\n",
              " ' les garde de de, Président, exercice du de ne pas être de temps de le position exemple sujet à bras lele-corps.Je la la la la',\n",
              " \" été un'  la bases de' une nouveau de retraite de, son.        que que que que que,,,,\",\n",
              " \" été trouvernons à. et nous' a pas eu' excuseclusments les mal. la il la à la être communauté de' êtreayer de vaincre\",\n",
              " \" les,, qui laquierdo que' en est mieux mieux être les nombre de TVA que la' économie que de stimuler les' environnement des nous le le\",\n",
              " \" été, aborder pour concert pour les partenaires pour que une les même chose des la' œuvrero la' austérité. le vies.dépenddépenddépenddépenddépend\",\n",
              " 'ons-vous nous à la question? de je ne lave? études?................',\n",
              " \" été,1 année, cette d d' autres,, à droits de, est' ont pas une.e ce ce l l l l l l l\",\n",
              " \" monde de la de' Etat, en la' influenceé de le vie. affaiblir années à venir.,,,,,,, et et et et\",\n",
              " \" été, la ne vient à des conclusion de' un homme de des humain de., à destination dans une port. pleinant des deux. Le l l\",\n",
              " \" été que à football de dans la efforts de par la sûr et' accès sur la principes de des briser la plus équitable équitable des des des,,\",\n",
              " ' été, l dialogue et plus large possible, - ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (',\n",
              " \" été que la niveau de pour tous deux futures.� santé de' uneiter dans vie à et           \",\n",
              " \". de de de réseauoduc.' unerogène. àont la échanges gaz' informationsergie entre et les' Europeth et l Pacifique-Orient et l\",\n",
              " ' monde, un\\' un à la confiance de la\\' activité,, la la demande en. les deux.. en les \" de villes ville, \" la',\n",
              " ' monde est l l\\' objet d\\' une travail approfondi \" la,,,,,,, ( ( ( ( ( ( (,,,,,',\n",
              " \"ons  que nouveau, l ou. propos' attention de la. deraudía MMargallo. Ggal, de M de.ppi. -\",\n",
              " \" été ne qui que' elles leur rappel, neraient la impossible la les autorité aérienne' assurance de pour personne de' exercice dans la' assuré qu clients de\",\n",
              " \" monde-Uni,2 Royaume gouvernement de de fait un sérieux doutes sur la' issueortement de la de l' accordope.eu le le le le le\",\n",
              " 'ons  un : revoir que, neions mal de fait que propos. que nous laraudy raison sa confiance. \" la la la la la la la',\n",
              " \" les' enus que vous suite de vous  entreprise entreprise de mettre, main. les temps. je.  question des le systèmeien sera ter dans\",\n",
              " ' été est de de la santé, de notre capacité, de en\\' en de la en sérieux la \" des tous membres, de nos- à.\\' ils',\n",
              " \" les que la année de régler pas être la. et qu nous temps que' à des ne peut être trouvé. les' immédiat actuel des choses. - (\",\n",
              " 'onsz, et besoins du votre secteur de, à l façon de� monde plus � temps-ci �        ',\n",
              " \" monde des l, que amendement. que' il estuirait de portée du bénéficient États membres ont besoin pour de' affronter avec questions aussi plus.Mee\",\n",
              " ' les la\\' enerai, attention collègue. depianen, les moyens que la \" de. les,es par les groupe nombre de\\'',\n",
              " ' les, la\\' est un plus la tout nous poser poser à de prochaines élections. des prochains mois. \"\\'\\'\\'\\'\\'\\'\\'\\'\\'\\'',\n",
              " ' monde de la Commission fait pas compte compte de \" de la de l\\' air intérieur les autres en à l\\' adhésion de elle la que\\' à est',\n",
              " \" les temps, de la ministre des donc' intention de des montant la' avenir des' animaux de marché temps. le de rétor, de\",\n",
              " 'ons garde2 la, la,, la \", l\\' égardiltation des laonsum, de lium, la des lourds à la vie de',\n",
              " 'ons, les \" quiquées pour port de leur vie pour bord de leur detais, aujourd\\' hui, les \" de le possibilité de de les et \"',\n",
              " ' été, en sur la façon, d pays des de les autres non, consacrer consacrer consacrer consacrer consacrermismis consacrer consacrer consacrer consacrer consacrer consacrer consacrer consacrer consacrer',\n",
              " ' années de train,-, sont que de taxes sur.. \" la la l l l la la la la la la la la la la la la la',\n",
              " ' été que de travail avec long les niveaux. la que aux bien aux possible aux besoins de besoins des marché. desber les \". le marché de la santé',\n",
              " \"ons' un de de un' amiable, de' est pas la, la la la' affaireiche de la autre :. un des autre de solution.\",\n",
              " ' monde sur l remarque aborder est- de ce question, que, question de la matière privée un \" public services est des des problèmes de- de la concurrence d',\n",
              " \" été que professionnel de intérêts ddémocrates au, il est que' accord l' Union comme l' est comme une' un des plus les la' issue\",\n",
              " \" les l l pas,' un, temps' issue,port, la,5' en'ai pas êtreêtre un autre l' autreéroport de\",\n",
              " \" monde de que,, et les deux de la, que nous les sommes la les valeur. la nous, nous' un ferroviaire est chemins de fer est la\",\n",
              " \"ée passé de la' unlisation de' un (,, les informations et à être que' ils ne être un rôle dans le vie contre le tabagisme.\",\n",
              " ' été par la \" de la plus,.Nous la la la la..... la, de de le Monsieur Monsieur Monsieur Monsieur Monsieur Monsieur Monsieur',\n",
              " \" monde de, Royaume,, fait des décision de' arrêtés pour pour stimuler à problème. en particulier compris la mise d l de' accord de les société,\",\n",
              " ' été, en contre les \" deales de qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui',\n",
              " \"ons  que vous  nombreux de mesure de' en faire des conclusions que de nous pourronsons des moyen de plus sûr pour' en que des acte ne se\",\n",
              " 'ons à de se la sens de \",, la pays,,, des à même de \" de marché unique. point aux.Le,,,,',\n",
              " \"és est un des qui accomplir je est satta astreler. toute. un autres deLe'''''''''''''\",\n",
              " \"ons de- vous de de, Président, de vous que point point détail., trait l importance. la débat' aujourd crise de résolution -'\",\n",
              " 'ables sont toutesées par des loi de temps et... les les les les les les à à à à à........',\n",
              " ' être qui est de la \" de \", la,iers, la est trait débat, première occasions, les passé,-moi,\\' en l',\n",
              " \"és est un plus de,2 la l avec des plus de' économie, la' elles nous' yagent à dans la les normes de par les droit\",\n",
              " \" été,, la' aspectcessi à savoir du travail, stimuler stimuler stimuler stimuler stimuler\",\n",
              " 'onser la à une de problème. de contre. \" la la la la la la la,,,,,,,,,,,,,',\n",
              " ' été, pour l \" sur vives de les pays de\\' originef centrale et\\' à la Chine de-pacifique........',\n",
              " \" été sortie, Paris est été comme nouveau années comme l radio de la, a' est marié sur la problèmes de l' Angleterreitat. la ville.Il\",\n",
              " \" monde estigne, la yeux ettatrices que vies humaines que' a subies les France et la Mali ces2 l suite de attentats attaques qui des dé bilan de\",\n",
              " \" monde façon à vous monde peut et faire est'��  est de' appeleroncerager les débat ministreatero à la rôle pour les forces\",\n",
              " ' été, main les partenaires pour que contre le qui \"\\' est le sur des êtres humains. a que que que que que que appeler appeler appeler appeler',\n",
              " 'ons  du le : et l\\' en vu de la \", \" ADN que la tests ne question sont sont pas des faits. \"\\'\\'\\'\\'',\n",
              " \" les' est pour pour cette que l l que la n de l' occasion pour appeler sa nouveau fois de comptes son préoccupation préoccupation face à fait que\",\n",
              " ' étéendrait des meilleurs neige des vue \" de la sur de en maintenant de touche à besoins les à temps. Le         ',\n",
              " \" été de' éléments de qui à,, traités lors les suite dansLa la la-----------    \",\n",
              " \" été que, ne pouvons que de de la technologie, la qui, G, mais aussi de' un vue de plus pour aborder à et façonner la relations\",\n",
              " ' les que la Chinois de sont pays de venir régléstus par efficacement que des5 des, la moyens deaux deLes la la la la la la la la',\n",
              " \"ée vaut, la' à l et ce reste de qu à les mois nécessaires le compte en. lui de verser les frais sommes de' elleera la projet\",\n",
              " 'ée, la est a des autre entre entre l politique. qui cette titre. que que \" \" est est de de la voie problèmes les nous les les',\n",
              " \" été de que la n' enions plus de de' argentergie pour nous la' atlantiqueoriz. etnininininininininini\",\n",
              " ' été à question de les deux- de les mêmes qu les données pratiques en la de protection des l données. il d de la rapport, desbitablement des',\n",
              " ' été la l, sur les propos de par le président ministre,,. Leoon, qui sujet de \" joué Parlement dans la crise de\\' idées que',\n",
              " ' est, des et \" de le que de fait de lequel il Commission de été entreprise. \" la la la la la la la la la la la la la',\n",
              " \" les lissais, de' une même table les responsables des la' ensemble, de, autres, lesiez-vous de les voir à nous? la\",\n",
              " \" les' après, et à pour,, la le garde un' écho de l - par la médias sens - la traitons -, la  ces pas\",\n",
              " \" été et, la fait de commissaire que quelle très que manière de' une des approcheistique de les question-économique des plus. - (\",\n",
              " ' les problème-corpstière a, étéosé son nom \", la passeport, la l été de sanglots. \" \" \" \" \" \" \" \" \" \"',\n",
              " \" les sens de de la décision quiente et à les' absenceanimité plus les quevant la' exerciceistenceitation de de potentiel.. l leUnion\",\n",
              " ' être question membre,, la vousons à une examen l d à un organisme de.',\n",
              " 'ons, la \" de vie est l de pour de modifications ces ces l, fait opportunités en cause. les suite. marché\\' Union. Le\\'\\'\\'',\n",
              " ' années de,, de plus difficultés de développement l exportations d,Les la la la la la la la la la la la la la la la la la la',\n",
              " ' hui den Bro,, à,\\' avais des dans \" de la. deverert. \",,,,, la la la la la la la',\n",
              " ' monde de les permis de de les droit sur les services de de de cadre de de sûr, sûr lequel les entreprises des des respectés......',\n",
              " \" été la nombreux, recherche dernières années, la' un de le le portée recherche de terme de technologie-culateurs s des. plus pluscalculateurs les\",\n",
              " \" les à'  à vous hommage à la deux qui à leurs remercier pour' êtreoci la de après jour, la rôle en. de de de de de\",\n",
              " ' été à se poursuivre, avec la le que la situation de de les progrès de Parlementateur à favorablement les recommandations. -ronsronsronsrons',\n",
              " ' monde de suite à la\\' accord de\\' une \" de l les retraites de\\' avion, qui pas est l pas être une réponse réponse à dans',\n",
              " 'ons la \" de la ladon, la \",, elle\\' est- problème qui la- bien se\\' occuper la commissaire et donné que\\' il',\n",
              " ' monde à cette question de de part-elle par une de régulation?.                ',\n",
              " 'ons  pas pas de même résolution que, vie, être une de de de de de de de de de de de de de de de de de de de',\n",
              " ' étéqui ici les ce partie les\\' aspect de\\' une, \" de garantie pour à paysations des qui qui nous s pas que que comme une simple de',\n",
              " \" été de d' être trouvée, les la est à injecter les recherche des plus à-mêmes. la vie politique. leur' Union.La'''\",\n",
              " ' monde de le l le à le Hamas américain et le Premier ministre Benjaminmert, été été annulée. a le a-, les Palestiniens de Hamas7 et',\n",
              " ' les une que\\' à un\\' argent de \", parvenir en mesure de nous le accord accord années parties \" -\\'\\'\\'\\'\\'',\n",
              " ' les\\' on des deux estcte la maladie, l ne- il le? ce monde? \" ( ( ( ( ( ( ( ( ( la ( (']"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "predicted_token_ids = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# Step 2: Decode the predicted token IDs to text\n",
        "decoded_predictions = [tokenizer.decode(pred_seq, skip_special_tokens=True) for pred_seq in predicted_token_ids]\n",
        "decoded_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uJoL29Nf1UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9703c69-f4b1-41ae-d1de-ed4dc84286f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  ',\n",
              " 'nous prendre problème à bras le corps',\n",
              " '  ',\n",
              " 'Turquie emprunter voie',\n",
              " '  ',\n",
              " '  ',\n",
              " 'je poursuivre remarque',\n",
              " 'directive toucher à question',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " ' stimuler de activité',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " 'gouvernement émettre doute',\n",
              " '  ',\n",
              " 'confiance se retrouver en lambeaux',\n",
              " 'nous sattaquer à question',\n",
              " 'abandonner proposition ',\n",
              " '  ',\n",
              " ' aborder problème',\n",
              " 'collègue répondre à inquiétude',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " ' résorber inégalité',\n",
              " 'je clôturer affaire',\n",
              " 'je soulever point',\n",
              " '  ',\n",
              " 'je décrocher emploi',\n",
              " '  ',\n",
              " 'il lutter contre problème',\n",
              " 'nous affronter défi',\n",
              " '  ',\n",
              " '  ',\n",
              " 'nous trouver moyen',\n",
              " 'autorité saisir concept',\n",
              " ' satteler à tâche',\n",
              " 'je préciser point',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " 'Rejeter être source de confusion',\n",
              " '  ',\n",
              " 'il se pencher sur problème',\n",
              " '  ',\n",
              " 'le Premier ministre trouver terrain dentente',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " 'aspect être aborder ',\n",
              " '  ',\n",
              " 'problème être combattre ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " 'traitement de problème ',\n",
              " 'relance de économie',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " 'mesure pallier problème',\n",
              " '  ',\n",
              " 'bouleversement constitue remise en question',\n",
              " 'industrie stimuler économie',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " '  ',\n",
              " 'être réponse à la crise ',\n",
              " '  ',\n",
              " '  ',\n",
              " 'solution être dégager ',\n",
              " 'le dirigeant aborder question',\n",
              " '  ',\n",
              " 'un animal contracter maladie']"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "decoded_labels = [tokenizer.decode(label_seq, skip_special_tokens=True) for label_seq in labels]\n",
        "decoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvhJiq_OgYhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b774b641-e5ac-4465-95aa-1dda246a9e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  , Prediction:ée que,, des des,� nous que nous l marché en commun nos énergie � notre efforts �' actionsergie �       \n",
            "Label:nous prendre problème à bras le corps, Prediction: les garde de de, Président, exercice du de ne pas être de temps de le position exemple sujet à bras lele-corps.Je la la la la\n",
            "Label:  , Prediction: été un'  la bases de' une nouveau de retraite de, son.        que que que que que,,,,\n",
            "Label:Turquie emprunter voie, Prediction: été trouvernons à. et nous' a pas eu' excuseclusments les mal. la il la à la être communauté de' êtreayer de vaincre\n",
            "Label:  , Prediction: les,, qui laquierdo que' en est mieux mieux être les nombre de TVA que la' économie que de stimuler les' environnement des nous le le\n",
            "Label:  , Prediction: été, aborder pour concert pour les partenaires pour que une les même chose des la' œuvrero la' austérité. le vies.dépenddépenddépenddépenddépend\n",
            "Label:je poursuivre remarque, Prediction:ons-vous nous à la question? de je ne lave? études?................\n",
            "Label:directive toucher à question, Prediction: été,1 année, cette d d' autres,, à droits de, est' ont pas une.e ce ce l l l l l l l\n",
            "Label:  , Prediction: monde de la de' Etat, en la' influenceé de le vie. affaiblir années à venir.,,,,,,, et et et et\n",
            "Label:  , Prediction: été, la ne vient à des conclusion de' un homme de des humain de., à destination dans une port. pleinant des deux. Le l l\n",
            "Label:  , Prediction: été que à football de dans la efforts de par la sûr et' accès sur la principes de des briser la plus équitable équitable des des des,,\n",
            "Label:  , Prediction: été, l dialogue et plus large possible, - ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( ( (\n",
            "Label:  , Prediction: été que la niveau de pour tous deux futures.� santé de' uneiter dans vie à et           \n",
            "Label:  , Prediction:. de de de réseauoduc.' unerogène. àont la échanges gaz' informationsergie entre et les' Europeth et l Pacifique-Orient et l\n",
            "Label: stimuler de activité, Prediction: monde, un' un à la confiance de la' activité,, la la demande en. les deux.. en les \" de villes ville, \" la\n",
            "Label:  , Prediction: monde est l l' objet d' une travail approfondi \" la,,,,,,, ( ( ( ( ( ( (,,,,,\n",
            "Label:  , Prediction:ons  que nouveau, l ou. propos' attention de la. deraudía MMargallo. Ggal, de M de.ppi. -\n",
            "Label:  , Prediction: été ne qui que' elles leur rappel, neraient la impossible la les autorité aérienne' assurance de pour personne de' exercice dans la' assuré qu clients de\n",
            "Label:gouvernement émettre doute, Prediction: monde-Uni,2 Royaume gouvernement de de fait un sérieux doutes sur la' issueortement de la de l' accordope.eu le le le le le\n",
            "Label:  , Prediction:ons  un : revoir que, neions mal de fait que propos. que nous laraudy raison sa confiance. \" la la la la la la la\n",
            "Label:confiance se retrouver en lambeaux, Prediction: les' enus que vous suite de vous  entreprise entreprise de mettre, main. les temps. je.  question des le systèmeien sera ter dans\n",
            "Label:nous sattaquer à question, Prediction: été est de de la santé, de notre capacité, de en' en de la en sérieux la \" des tous membres, de nos- à.' ils\n",
            "Label:abandonner proposition , Prediction: les que la année de régler pas être la. et qu nous temps que' à des ne peut être trouvé. les' immédiat actuel des choses. - (\n",
            "Label:  , Prediction:onsz, et besoins du votre secteur de, à l façon de� monde plus � temps-ci �        \n",
            "Label: aborder problème, Prediction: monde des l, que amendement. que' il estuirait de portée du bénéficient États membres ont besoin pour de' affronter avec questions aussi plus.Mee\n",
            "Label:collègue répondre à inquiétude, Prediction: les la' enerai, attention collègue. depianen, les moyens que la \" de. les,es par les groupe nombre de'\n",
            "Label:  , Prediction: les, la' est un plus la tout nous poser poser à de prochaines élections. des prochains mois. \"''''''''''\n",
            "Label:  , Prediction: monde de la Commission fait pas compte compte de \" de la de l' air intérieur les autres en à l' adhésion de elle la que' à est\n",
            "Label:  , Prediction: les temps, de la ministre des donc' intention de des montant la' avenir des' animaux de marché temps. le de rétor, de\n",
            "Label:  , Prediction:ons garde2 la, la,, la \", l' égardiltation des laonsum, de lium, la des lourds à la vie de\n",
            "Label:  , Prediction:ons, les \" quiquées pour port de leur vie pour bord de leur detais, aujourd' hui, les \" de le possibilité de de les et \"\n",
            "Label:  , Prediction: été, en sur la façon, d pays des de les autres non, consacrer consacrer consacrer consacrer consacrermismis consacrer consacrer consacrer consacrer consacrer consacrer consacrer consacrer consacrer\n",
            "Label:  , Prediction: années de train,-, sont que de taxes sur.. \" la la l l l la la la la la la la la la la la la la\n",
            "Label: résorber inégalité, Prediction: été que de travail avec long les niveaux. la que aux bien aux possible aux besoins de besoins des marché. desber les \". le marché de la santé\n",
            "Label:je clôturer affaire, Prediction:ons' un de de un' amiable, de' est pas la, la la la' affaireiche de la autre :. un des autre de solution.\n",
            "Label:je soulever point, Prediction: monde sur l remarque aborder est- de ce question, que, question de la matière privée un \" public services est des des problèmes de- de la concurrence d\n",
            "Label:  , Prediction: été que professionnel de intérêts ddémocrates au, il est que' accord l' Union comme l' est comme une' un des plus les la' issue\n",
            "Label:je décrocher emploi, Prediction: les l l pas,' un, temps' issue,port, la,5' en'ai pas êtreêtre un autre l' autreéroport de\n",
            "Label:  , Prediction: monde de que,, et les deux de la, que nous les sommes la les valeur. la nous, nous' un ferroviaire est chemins de fer est la\n",
            "Label:il lutter contre problème, Prediction:ée passé de la' unlisation de' un (,, les informations et à être que' ils ne être un rôle dans le vie contre le tabagisme.\n",
            "Label:nous affronter défi, Prediction: été par la \" de la plus,.Nous la la la la..... la, de de le Monsieur Monsieur Monsieur Monsieur Monsieur Monsieur Monsieur\n",
            "Label:  , Prediction: monde de, Royaume,, fait des décision de' arrêtés pour pour stimuler à problème. en particulier compris la mise d l de' accord de les société,\n",
            "Label:  , Prediction: été, en contre les \" deales de qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui qui\n",
            "Label:nous trouver moyen, Prediction:ons  que vous  nombreux de mesure de' en faire des conclusions que de nous pourronsons des moyen de plus sûr pour' en que des acte ne se\n",
            "Label:autorité saisir concept, Prediction:ons à de se la sens de \",, la pays,,, des à même de \" de marché unique. point aux.Le,,,,\n",
            "Label: satteler à tâche, Prediction:és est un des qui accomplir je est satta astreler. toute. un autres deLe'''''''''''''\n",
            "Label:je préciser point, Prediction:ons de- vous de de, Président, de vous que point point détail., trait l importance. la débat' aujourd crise de résolution -'\n",
            "Label:  , Prediction:ables sont toutesées par des loi de temps et... les les les les les les à à à à à........\n",
            "Label:  , Prediction: être qui est de la \" de \", la,iers, la est trait débat, première occasions, les passé,-moi,' en l\n",
            "Label:  , Prediction:és est un plus de,2 la l avec des plus de' économie, la' elles nous' yagent à dans la les normes de par les droit\n",
            "Label:  , Prediction: été,, la' aspectcessi à savoir du travail, stimuler stimuler stimuler stimuler stimuler\n",
            "Label:Rejeter être source de confusion, Prediction:onser la à une de problème. de contre. \" la la la la la la la,,,,,,,,,,,,,\n",
            "Label:  , Prediction: été, pour l \" sur vives de les pays de' originef centrale et' à la Chine de-pacifique........\n",
            "Label:il se pencher sur problème, Prediction: été sortie, Paris est été comme nouveau années comme l radio de la, a' est marié sur la problèmes de l' Angleterreitat. la ville.Il\n",
            "Label:  , Prediction: monde estigne, la yeux ettatrices que vies humaines que' a subies les France et la Mali ces2 l suite de attentats attaques qui des dé bilan de\n",
            "Label:le Premier ministre trouver terrain dentente, Prediction: monde façon à vous monde peut et faire est'��  est de' appeleroncerager les débat ministreatero à la rôle pour les forces\n",
            "Label:  , Prediction: été, main les partenaires pour que contre le qui \"' est le sur des êtres humains. a que que que que que que appeler appeler appeler appeler\n",
            "Label:  , Prediction:ons  du le : et l' en vu de la \", \" ADN que la tests ne question sont sont pas des faits. \"''''\n",
            "Label:  , Prediction: les' est pour pour cette que l l que la n de l' occasion pour appeler sa nouveau fois de comptes son préoccupation préoccupation face à fait que\n",
            "Label:  , Prediction: étéendrait des meilleurs neige des vue \" de la sur de en maintenant de touche à besoins les à temps. Le         \n",
            "Label:aspect être aborder , Prediction: été de' éléments de qui à,, traités lors les suite dansLa la la-----------    \n",
            "Label:  , Prediction: été que, ne pouvons que de de la technologie, la qui, G, mais aussi de' un vue de plus pour aborder à et façonner la relations\n",
            "Label:problème être combattre , Prediction: les que la Chinois de sont pays de venir régléstus par efficacement que des5 des, la moyens deaux deLes la la la la la la la la\n",
            "Label:  , Prediction:ée vaut, la' à l et ce reste de qu à les mois nécessaires le compte en. lui de verser les frais sommes de' elleera la projet\n",
            "Label:  , Prediction:ée, la est a des autre entre entre l politique. qui cette titre. que que \" \" est est de de la voie problèmes les nous les les\n",
            "Label:  , Prediction: été de que la n' enions plus de de' argentergie pour nous la' atlantiqueoriz. etnininininininininini\n",
            "Label:traitement de problème , Prediction: été à question de les deux- de les mêmes qu les données pratiques en la de protection des l données. il d de la rapport, desbitablement des\n",
            "Label:relance de économie, Prediction: été la l, sur les propos de par le président ministre,,. Leoon, qui sujet de \" joué Parlement dans la crise de' idées que\n",
            "Label:  , Prediction: est, des et \" de le que de fait de lequel il Commission de été entreprise. \" la la la la la la la la la la la la la\n",
            "Label:  , Prediction: les lissais, de' une même table les responsables des la' ensemble, de, autres, lesiez-vous de les voir à nous? la\n",
            "Label:  , Prediction: les' après, et à pour,, la le garde un' écho de l - par la médias sens - la traitons -, la  ces pas\n",
            "Label:  , Prediction: été et, la fait de commissaire que quelle très que manière de' une des approcheistique de les question-économique des plus. - (\n",
            "Label:  , Prediction: les problème-corpstière a, étéosé son nom \", la passeport, la l été de sanglots. \" \" \" \" \" \" \" \" \" \"\n",
            "Label:mesure pallier problème, Prediction: les sens de de la décision quiente et à les' absenceanimité plus les quevant la' exerciceistenceitation de de potentiel.. l leUnion\n",
            "Label:  , Prediction: être question membre,, la vousons à une examen l d à un organisme de.\n",
            "Label:bouleversement constitue remise en question, Prediction:ons, la \" de vie est l de pour de modifications ces ces l, fait opportunités en cause. les suite. marché' Union. Le'''\n",
            "Label:industrie stimuler économie, Prediction: années de,, de plus difficultés de développement l exportations d,Les la la la la la la la la la la la la la la la la la la\n",
            "Label:  , Prediction: hui den Bro,, à,' avais des dans \" de la. deverert. \",,,,, la la la la la la la\n",
            "Label:  , Prediction: monde de les permis de de les droit sur les services de de de cadre de de sûr, sûr lequel les entreprises des des respectés......\n",
            "Label:  , Prediction: été la nombreux, recherche dernières années, la' un de le le portée recherche de terme de technologie-culateurs s des. plus pluscalculateurs les\n",
            "Label:  , Prediction: les à'  à vous hommage à la deux qui à leurs remercier pour' êtreoci la de après jour, la rôle en. de de de de de\n",
            "Label:  , Prediction: été à se poursuivre, avec la le que la situation de de les progrès de Parlementateur à favorablement les recommandations. -ronsronsronsrons\n",
            "Label:  , Prediction: monde de suite à la' accord de' une \" de l les retraites de' avion, qui pas est l pas être une réponse réponse à dans\n",
            "Label:  , Prediction:ons la \" de la ladon, la \",, elle' est- problème qui la- bien se' occuper la commissaire et donné que' il\n",
            "Label:être réponse à la crise , Prediction: monde à cette question de de part-elle par une de régulation?.                \n",
            "Label:  , Prediction:ons  pas pas de même résolution que, vie, être une de de de de de de de de de de de de de de de de de de de\n",
            "Label:  , Prediction: étéqui ici les ce partie les' aspect de' une, \" de garantie pour à paysations des qui qui nous s pas que que comme une simple de\n",
            "Label:solution être dégager , Prediction: été de d' être trouvée, les la est à injecter les recherche des plus à-mêmes. la vie politique. leur' Union.La'''\n",
            "Label:le dirigeant aborder question, Prediction: monde de le l le à le Hamas américain et le Premier ministre Benjaminmert, été été annulée. a le a-, les Palestiniens de Hamas7 et\n",
            "Label:  , Prediction: les une que' à un' argent de \", parvenir en mesure de nous le accord accord années parties \" -'''''\n",
            "Label:un animal contracter maladie, Prediction: les' on des deux estcte la maladie, l ne- il le? ce monde? \" ( ( ( ( ( ( ( ( ( la ( (\n"
          ]
        }
      ],
      "source": [
        "# human comparison:\n",
        "for label,prediction in zip(decoded_labels,decoded_predictions):\n",
        "  print(f'Label:{label}, Prediction:{prediction}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHXeLd5Po5WN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUlDUoVeBJTO"
      },
      "outputs": [],
      "source": [
        "# Transfer learning script\n",
        "\n",
        "# Load data into the custom dataset\n",
        "My_dataset_eng = MaskedTextDataset(df=eng_df_all, tokenizer=tokenizer)\n",
        "# Split into training and test sets\n",
        "split = 0.8\n",
        "train_eval_size_eng = int(split * len(My_dataset_eng))\n",
        "test_size_eng = len(My_dataset_eng) - train_eval_size_eng\n",
        "train_eval_data_eng, test_data_eng = random_split(My_dataset_eng, [train_eval_size_eng, test_size_eng])\n",
        "\n",
        "My_dataset_ger = MaskedTextDataset(df=ger_df_all, tokenizer=tokenizer)\n",
        "train_eval_size_ger = int(split * len(My_dataset_ger))\n",
        "test_size_ger = len(My_dataset_ger) - train_eval_size_ger\n",
        "train_eval_data_ger, test_data_ger = random_split(My_dataset_ger, [train_eval_size_ger, test_size_ger])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "08keuap9fFx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels, metrics = trainer.predict(test_dataset=test_data_eng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "M_ZjmYyoe9ZF",
        "outputId": "d5d01ff6-0edd-4598-f172-0833b0265a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_token_ids = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# Step 2: Decode the predicted token IDs to text\n",
        "decoded_predictions = [tokenizer.decode(pred_seq, skip_special_tokens=True) for pred_seq in predicted_token_ids]\n",
        "decoded_labels = [tokenizer.decode(label_seq, skip_special_tokens=True) for label_seq in labels]\n",
        "# human comparison:\n",
        "for label,prediction in zip(decoded_labels,decoded_predictions):\n",
        "  print(f'Label:{label}, Prediction:{prediction}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDi-ApYrfBri",
        "outputId": "b91b458e-afed-4088-aa16-85c3948c805f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:we kill off program, Prediction:onstonter  'yfic, theinding the a whos. havegue' t theing onÂ la la la la la la la'\n",
            "Label:  , Prediction: étéons the year the place leadinary, of thetermination to the de who wasaped the a car, in in a way dayy. the\n",
            "Label:  , Prediction: mondepartment s,'' s oning,000-1 victor000 a 3erson' run. the firstth inning.000 the notppedta\n",
            "Label:  , Prediction: est, ,lly, to doach awayzybt,P la la la la la la la''''''''\n",
            "Label:  , Prediction:ons, qui unérantaire,aceler, who wasdles the a ndom'er. of the mostviouscks hales ofver.d\n",
            "Label:newsletter attack this, Prediction:ons de close of tolytokette.ction. help the.T l l l l l l l l l l livre    \n",
            "Label:water be poured , Prediction:ons, been ared by the gr since the othervisd been aed.. the ownffic. said s s saide'.'les les\n",
            "Label:  , Prediction:ésing the governmentagues have notamed tchedver to doy the, he were not mores liager to have him ownatherts. to they\n",
            "Label:  , Prediction:ée.e.ke qui formerress,mer, isd a a acres in the,ans, yearing, according a ofandir of a as\n",
            "Label:  , Prediction: estositions,..ts by economypartmenttrators, aet,000ty.appeing, aise.icel.Â la la la,\n",
            "Label:  , Prediction:onsach, detimead, theh-aks, butk.ron,pped a a \"ing \"anding \"tic.im. whichez\n",
            "Label:  , Prediction:onsantic,rently. beented a the aators in the si, \" la l l l l l l l la la la la la la la\n",
            "Label:  , Prediction: monde,,'olve theonsyle, a otherhere. the dew years. the.ours.eping on the way of the of the\n",
            "Label:  , Prediction:és,,00kok,sgs a nhaw, in theoa,y on takeend a on the in the notd Le la,\n",
            "Label:  , Prediction:ons,ings areuterents are theyown as \"-, are the to theted theodsh which said to the-dies, the nod,\n",
            "Label:Support melt away , Prediction:ons the Futureipmentsard,ke,gan ont feway from iters wereross theand wered thearity' planpes ay\n",
            "Label:  , Prediction: étéat monthsantsoustors,ed aine,t, a a $ percent. getolve the a faceormach.com la la la Le\n",
            "Label:  , Prediction:ons,,,irman, Kerryddrence, saidged as a mosting Republic for theill the economy presidat in the Sen Bureauerve''\n",
            "Label:  , Prediction:onsd,, the Universityaf Departmentteligence Agency, it the the U.S. militaryes not wantd Unitedities to do in Uian\n",
            "Label:  , Prediction: monde Bushod to to the-J90 to000ing the action military sanctions to the, agh police wereoun to the of officials saidecked\n",
            "Label:  , Prediction:éeilib,, a onlyarest companyture of the globalrup selfworkorth of the sharesility to make theal asseosses.Â l l\n",
            "Label:A Bright Shining Lie be attacked those who trimmed their judgments, Prediction: étén,ing, \" be acked by a who have beenmed the owngmentments on the timecade. s.viousing thes on\n",
            "Label:  , Prediction: mondeal governmentrier, itansingtory000 \" otherage of theailable,ctor wered with000alsased by the percenting the6\n",
            "Label:  , Prediction:onsren'gue,olorelind, desers by,, and a beenried. wereired the to \" ( ( ( ( ( ( ( (\n",
            "Label:  , Prediction:ons, a a only time for hero '', beenued theentteross the economyle.fensived sidetier. hadght to\n",
            "Label:the industry attack the competition, Prediction: mondeach, noting theachesrows on the United eleustry.re hasates dolec the theers the epetittition. theingW\n",
            "Label:  , Prediction:onston. deidanuis, the wasinks the company' beenken aps toward its.ms.W la la la la la la la\n",
            "Label:  , Prediction: mondeement,ok aputoenorureb ( HC ) ).yed se ) s )ctive ) )ste )rok )way\n",
            "Label:  , Prediction:éeket.annel,gue' t! bely make a more theef, they'�u the thewnd fromoutaplytry.T\n",
            "Label:  , Prediction:és theterd in Wednesday 3,000 was a dayss, was convicistearly underesseted by a Kore officials.Â la la la la la\n",
            "Label:Mr. Mitterrand dissolve the National Assembly, Prediction:onston,sists say the the theaming a \"ist partyledated economy,e.P' \"arly aying to winoke a \"ative\n",
            "Label:independent-minded unit lend aid, Prediction: mondeement, saidpe theoid aillionsering, theans and the rivalpendent subsidieded subsidi, which isdged to buyose itselfity\n",
            "Label:  , Prediction: étéine,, the,, the-and. alsoachwhere.000 oflying their sameologyical systemart of the economyels.,\n",
            "Label:  , Prediction:onso thes............................\n",
            "Label:  , Prediction:és,, ad to make the controlly watermo of theall-idersactors.W \" \" \" \" \" \" \" \" \" \"\n",
            "Label:  , Prediction:onston the governmenters wereve a carls, the n,,000 policekntended,ellow,e.way.000yingk.art\n",
            "Label:  , Prediction:és, faceuc, a face.e.ock'' ssyle,'doate a it' been,d, e ofW la la\n",
            "Label:  , Prediction:ons,,' not000' m,ent, I economycientists are theoach'' the. \" ''''''\n",
            "Label:  , Prediction:ons,line,3d on thephia,000 it would to buylect on ownearchersted to the-'�,,sue,tic\n",
            "Label:  , Prediction: mondepper, \"or have a, other, the. theyting000ver. otherrink.out.W la la la la la la la la\n",
            "Label:Public judge besiege bureaucrat, Prediction:onsitégment, notal on000 court case..re wellthing to than theidesged..rats.Â la la Le Le Le Le\n",
            "Label:  , Prediction:ons,. et s , 'ed to buyend itsch'''a, Texas well as the 1 million, according the thechased of\n",
            "Label:  , Prediction:ons,,, a right to winisetice...cs. she law' had been aing onliineity the.ves. theyting\n",
            "Label:  , Prediction: mondeque,, not' t, air, yearinter. butens totead to ap. as aton, ainterels. were\n",
            "Label:  , Prediction:ée on the day, the U of theerves was couldks haveost toach other was the fell theage $ $ percent5 percent.T la la\n",
            "Label:  , Prediction: mondeaceful, which hasgetsted the groupJ52, saidally saidlained with Barack' helpancel a first' but it first- aitable\n",
            "Label:  , Prediction: monde timelindday, \" le firstmanes'ilt on a first Force' they' Air. \" aded out the n of.\n",
            "Label:the businessman grab customer, Prediction: été-,man,athe a a firstbage,bigh,,, saidckly,ried to getb aardsomer, the cmakers\n",
            "Label:  , Prediction:ée.e \"ontaine. que that the companyencing ofities were \"allylybil Friday,d of beingaultting thesomen.ounting\n",
            "Label:Mr. Marchese play a role, Prediction:ons firstencing, the. dekss, his fam,runointed famyer, a-. Gne, saidlained that the.\n",
            "Label:  , Prediction:onse been killedck by a un,ull, \" l l l l l l l l l l l l le le le le le le le le\n",
            "Label:  , Prediction:ons, ago. the''ineering have to with a theymed to \"ger proble to the proble' probleoding. the U Americant Lake\n",
            "Label:government officials play a role, Prediction:ons, said ago beenlained that the officials were the countries wereed interestressive role in the andelf..fareinery. \" l l l\n",
            "Label:  , Prediction:onstique,yed the sees of ated Islamists, the on the countries onÂ la la la la la la la la la la la la\n",
            "Label:This lend support, Prediction:ons, de to makeose onat than.S. c for theters. thanthersas.ars.W \" \" \" \" \" \" \" \"\n",
            "Label:  , Prediction: est,, youaulco, \" the' t aingieatra -- \" l l l l l l l l l l l l l les\n",
            "Label:  , Prediction:ée, theese areosses were be maded by the economyOM.,000 economyustry' s.te'ests said.Â la la\n",
            "Label:  , Prediction:ésal the economyarth-year-- thatriedingance onms thatreadyed them to attackke theet-gets.viousely. \" la\n",
            "Label:  , Prediction: monde,'ate a aart.' toing..ainying,andaktain.ail.ned into wayeng intooundments. a \"\n",
            "Label:  , Prediction:és. \"wal government,d the percent5 percentred the c domessct.y the, was beenased the $.5 billions8\n",
            "Label:Mr. Vanns life fill life, Prediction:ée.eiennentina s,, a veryormning,,eelf,ushant.aling aualitysions. haved a ownacy\n",
            "Label:  , Prediction: monde,yed the Airlines,' on sourceamin,000.,000 alyaryts.uring,,Â l l Le Le Le\n",
            "Label:  , Prediction: mondediers,il to makeolve the-aloiceesty,onsones, the years,000avingver.T \" \" \" \" \" \"\n",
            "Label:  , Prediction:ons mostilion \" qui. de.ington, ne.way monthass. \",,,,,,,,,,,,, est\n",
            "Label:the Court melt down statue, Prediction:onston depreme Court't with the own, he wascided toel,'W la la la la la la la la la la la\n",
            "Label:  , Prediction: été,ieged the thecialistests,d by'o'inopek,000 the dean-,.tive to the.ests.\n",
            "Label:  , Prediction: monde,, on expected firsttest in a stringluw of concern monthsearchers has been it moreasingly difficult to see the twouesuresup\n",
            "Label:gold and silver be dragged down platinum, Prediction: été une.000 prices silver rose downged down by than theunum prices expected the. pricestraating.L la la la la la la\n",
            "Label:  , Prediction: été,,es have to-its.ied'' t the awter than theed the markets. they had in theing pricesoline prices.\n",
            "Label:  , Prediction: étéignementop. et it initial of onesterday in the hospital of stage in the,ights, California.Y. \" a a people in injure\n",
            "Label:Sanctions destroy the economy, Prediction:ons. deyed deern nation,000 far000.000 be the first of aiseary mero economic moreasingary economic of.Â la\n",
            "Label:  , Prediction: monde.S. military saidrik at aelfims on the theding wereered the militarylight-borneyleage area in the near base in\n",
            "Label:Luby s Cafeterias Inc. target the Midwest, Prediction:ons,,,,ésia '. \" et Francisco, Texas, États ageting the Unitedwest, aly announing a a a ownwater\n",
            "Label:  , Prediction:ons,ly 1000 same' expecteding its a million 300 millionits of year.000 fromow theUE.�... the.000.\n",
            "Label:  , Prediction:ons, ago, de of calledd the situation' s onally on000ing to the next of a country Bay, Act, thetember..Â\n",
            "Label:conservative assault liberal, Prediction:ée,' economy administrationvolution, been under theot.000 beate have a the of. aero ofly. a' beenessted theity\n",
            "Label:investor escape malaise, Prediction:onsand,.,'ger,,2 étéology,sis, theper J s.ray, Associkins' aingapolis, a it expected\n",
            "Label:  , Prediction:ée.e, the company were beoustnndoniumdown a a a s s the hctions.. \" ( ( ( ( ( ( ( (\n",
            "Label:  , Prediction:onsité.,adyd in firstith on., when. in therylys wereed from of,h aried. butging a out\n",
            "Label:  , Prediction: été buttember, 2017 :23-old,yly,, theon Rouge, whote \" et aly injurerappedd by a de number\n",
            "Label:  , Prediction: monde.oday' s. ared toves with the other-.s arerared theunsT.S. \". aocknel.\n",
            "Label:player plow money, Prediction:ésdown,.ers. aal -- haveaysed their own -- the investorsal funds -- wholyal investors --eking to moreckly\n",
            "Label:  , Prediction:ons,. de,ays agreders, the. Bush, the firstoman-,. isars the famils he doceed. the\n",
            "Label:  , Prediction:ons,re : a \"-year-year-year-,000ffeed in a of-, ad a a otheruses. aes.\n",
            "Label:  , Prediction: est,se,000red a the economy of notle to do a theet men.ying to get a a theelsonger' s, to\n",
            "Label:  , Prediction:ons,2ing theory who s.ise. the, investorsals, the \" numberuring..000 saidound. economygins-'ly\n",
            "Label:  , Prediction: monde' the politicaliled state, the,000 wasaped the a \"ila-,,000 for the government to a n to stop stop to help\n",
            "Label:  , Prediction: été a very where do,ward thirdter time. but \" s said.'she fam' \"y sors,roun.ists.pped up\n",
            "Label:electronically controllable polymers lend themselves, Prediction:ée.e,, quiown asly as his \"ing theology,work, saidieves he thectronic-,lsing,mer are\n",
            "Label:  , Prediction:onsphoneonents,ying to make more. the.ings that the.ather.stftb economy. theend the.000 makemblly own\n",
            "Label:  , Prediction:onsA. \",2 écritesti, aife, the \"th century.000 : the000 theyingking,mplesuralaes, \"\n",
            "Label:  , Prediction:onsite, economyic' notac a they about aent athekce' which' t theyingings are me. the worldgedy of the\n",
            "Label:  , Prediction:ée Lynch',, aamed a \"or of the yearlity,000oun a $u thatÂ la la la Le Le Le Le Le Le\n",
            "Label:  , Prediction:ésants to government' doerstand what the economyitya economy,ddcle \"y been aelfility to dovive \" the years000 years\n",
            "Label:  , Prediction:ons,ing,mp,,,,aps'she wasoves'firstily'. 'ireate.wayw h ago. \" l\n",
            "Label:  , Prediction:és on, thecingample, the de of hasdes the R, s,at-anden-esressghter-ories at in\n",
            "Label:cigarette manufacturer escape the ban, Prediction:ée.e'son, the was s notclearirly theers,rs were havetisedout.S. c have beape their marketks\n",
            "Label:A philoopher roll into one, Prediction: étéer, etparer, philosophcian.omsd a a of and mostthyear-old'. and.,cht,urait'ing,\n",
            "Label:  , Prediction:ésisezs, thesyred by the singleh--ing-ottom. \",,,,, la la la la la les les\n",
            "Label:  , Prediction:ée.eech the000 s' '' not'�  ing on0'�t ed'       \n",
            "Label:  , Prediction:ée.eson, beenied any he wasried to doill himimself. he he wasumests his dauife.T la la la la\n",
            "Label:Heinz target country, Prediction:és,, ageted the a, the' the, the. the, the of a next economy' economytage. boostaseminate the.\n",
            "Label:Michael D. Dingman smooth over a rift, Prediction:ons, the,ulation thatetday. the officials would the' Coshire have been aly beenin..,.ler' aman of chief\n",
            "Label:  , Prediction:onsado,,.n by aical,,tayed the homes in ad a least one of. a ninaas,Â \"\n",
            "Label:opponents ride roughshod, Prediction:ons, aosesents ofainte the de' a \"-handed companykder. butding theghlyotsder thely \" la la\n",
            "Label:  , Prediction:ons,lienant, theally-dly the economylume of haveock out thees, otherildches, whichunging onretery,\n",
            "Label:director grasp quandary, Prediction: monde,ass, \"ked,or,wed by ownter-ts as aund,ants,, the group Bern-ed, wereiled\n",
            "Label:reporter and lawmaker examine the incentive and cost, Prediction: monderey \" beented thests whore who investorsmakers who have been moreous about see the issueomeves of thets ofÂ Le Le\n",
            "Label:  , Prediction: mondeices \"000ite devicesopment isww years ago, thew by a \"olutionary theas care.eergydtors to makeol\n",
            "Label:ads play down the dog, Prediction:onstonon.lyvice, be a the economy' ifther. thelayedway-eranreduns which  s'ound,, '\n",
            "Label:  , Prediction:ons,ts, thed to maket aing,, the watermoors,essel,W la labb les les les les les les les\n",
            "Label:  , Prediction:onston aly the whoates were beingyed by the of alain-,000 companyment' hasire to moreate. be to beait\n",
            "Label:  , Prediction: est, the Yeest level of themical we in the world' which mostopek ontory,oseled theope. whichmping theel\n",
            "Label:  , Prediction: mondeth banle,ments,lied a the Donald on expected000 a first power in000lythded economyals inueing theences their same\n",
            "Label:  , Prediction:ons, %00.dish,�  . onlyply beenown as their a�air.et.ross the border. thekey.\n",
            "Label:Ms. Myerson fix case, Prediction: mondeanment,gations that the.Bers' him Departmentb' s aghter, \" 1 million000- $-year-., the\n",
            "Label:  , Prediction: est, been be a in they' s beenall, but itantsed a' do itW'''''''''''\n",
            "Label:  , Prediction:és uneter to aoursday, the president economy. which Germanorist group said..Kffjyer, who was notablemed by the\n",
            "Label:Grand Metropolitan PLC knock down impediment, Prediction:onsolitan MuseumC. le sonting to helpock a the $gal,eachmental the ownd law, thefibury'. \"\n",
            "Label:documentary maker be strucked children, Prediction:onsand theised its the' theachated in a' where Universityoungestary.kes saidd a on the alsog in a governmentclear\n",
            "Label:  , Prediction:ésdles., a ndle of theouth. daybow, theaw, by- ag to beill aunelf. aestsling\n",
            "Label:  , Prediction:és sur a the,ario, the more the tradingulation that the centralun, theill the. and,al have beenally. a \"dle-\n",
            "Label:  , Prediction: étérique de ded the on whichowever, washead Bankalth Service official said. laartest snowise had the wind snows had expected to\n",
            "Label:federal investigator examine whether Peck employees may have emulated improper trading, Prediction:onsvreic,ators said said investiging theether thefi'ees were have beenulated a othervemently.Â Le Le Le Le Le\n",
            "Label:the moles plant a time bomb, Prediction: mondeirkine also aing it theyes asal. butned awaytionondeagement of.ing a are are of thethlation that \" les\n",
            "Label:Chicago aldermen besiege the statehouse, Prediction:ons ownners000,000'lowly were been killed closey fordaing for they ofcs haveoketged the de'. afield.\n",
            "Label:Efficiency destroy job, Prediction:éscy,esn' tnyed,000'ally. economyaky theate a jobs000 moreualally moreter jobs000.W\n",
            "Label:  , Prediction:és, ofelder,',misked thewayol, he scoreneked a singleman aor a a the 3-- run. the\n",
            "Label:  , Prediction:onsaires,rer,,2, of chair executive ofer,e they company'ly had beented its own- of a \" company.000\n",
            "Label:  , Prediction:és.d, %,t,00 \"chetists who saidd the ofers ofÂ la la la Le Le Le Le Le Le Le Le\n",
            "Label:  , Prediction:ons'ps to the country, the docomeing the \",'ary,,,,,,,,,,,,,,,,\n",
            "Label:They be filled idea, Prediction: monde, ad with aa,000 theyten they a deapon, of s that'' t a what they do.ything.W la\n",
            "Label:  , Prediction:onsler, said the governmentoming government- \" \"mped. the time of $.ls per oil, day. the yearth of $. but\n",
            "Label:  , Prediction: monde, not the situationms andrecially ifonalityuterers,000 help a they they theorities thes are be used toW\n",
            "Label:  , Prediction:ons of the world are be on the whoght toside theveringms. according just whoowning out thequartunters.es.W l\n",
            "Label:  , Prediction: mondediers,il to makeolve the-aloiceesty,onsones, the years,000avingver.T \" \" \" \" \" \"\n",
            "Label:  , Prediction:és- il été.h,ary,ur..,dentd onross the nands, aadalaya, thegan aing up n of\n",
            "Label:China pour dollar, Prediction:ons,lie,od of thousands of people. thets a economy' economy--tle of the.S.ledined countries- Bush\n",
            "Label:  , Prediction:ons' what youpendcy isans you \" \" ','le, \"ass, a owngesina' \" la la la la la la\n",
            "Label:  , Prediction:ons,tember,2,23-old,yly,, theon Rouge,23 plusK  aly injurerappedd in a de number\n",
            "Label:Communist Party leader drag their feet, Prediction:onstoning, government were the twoist Party' beend a of thearnity in s,formsope want notging out ownet onÂ\n",
            "Label:a forum target blacks and Hispanics, Prediction:éself to the thanity,dents, the'oined the in aLA' the University of California, UC, the University of Californiaern California\n",
            "Label:  , Prediction: étéine,,.ants takeduce averyate,re on the- the mostorcy s,, thevide that the theoutese me\n",
            "Label:  , Prediction:ons,pp, qui-ing, the otherl.front,light,,, saidtifyied on ae court on month that he.K\n",
            "Label:  , Prediction:ons,000S,partmenttraors onessted a governmentquarters of a the city and Drug Administration'side the,Âameameameame\n",
            "Label:cast member melt the heart, Prediction: étéworth,eulousness, the deter.est-t ofans of a samegestice.p to the economy. the of of be\n",
            "Label:  , Prediction:ons mostope' the attack,000ors, they were \"le to getape the car, awling the a least timean on the air.\n",
            "Label:Centralization kill motivation, Prediction:ésralstionum, qui le other side, theilling a, doushing. ballitit.Tthththththththth\n",
            "Label:  , Prediction:és,achos,,, ellelit,. the. the n half. but a socking up aine of sles.Â''\n",
            "Label:  , Prediction: étéineha sur,over a $ percent. makeolve the a faceunach.be la la la la Le Le Le Le Le Le Le Le\n",
            "Label:  , Prediction: été''k,, a a a first time since a years.000 lifepar to get to process.ade. aengtheninged byÂ\n",
            "Label:  , Prediction: été une.000 ofment in the the,000tically foreign investorsven the $ percentred the domessct. expected expected to of the cur\n",
            "Label:magazine executive grab buyer, Prediction:ons'��  y, iscute have theyffee the been beach a of thatb auyers haveW      \n",
            "Label:they kill it, Prediction: monde, been strong-read on the,000 theally the it wasens,'tely havene.. the. it s s a deary\n",
            "Label:the firm be dissolved , Prediction:onston, said the the were investors were the government wereed to they000en the.Troneing'��' hadd toacity to\n",
            "Label:Drexel plow money, Prediction: été une. theamsler, aented a than to theaged companiesbacksout, whichmentingingouts, the asseendsly asse\n",
            "Label:  , Prediction:ons,les, quiakist, the of the Departmentredmento Department,, saidlined to comment whether he' notgeted. whvi\n",
            "Label:  , Prediction: mondekey, s,'. expectedd by the companyild' s.ers groupds,W'''''''''''\n",
            "Label:Bundesbank lend support, Prediction: monde \".bank, Commcan to cut its interest hi Thursdayities,ayases,enciments, the.1 percent. points. the lowed-\n",
            "Label:  , Prediction:onsons,an,000 most of peoplever ind byh,000ased by $85 millionred the.2,red Le la la la\n",
            "Label:  , Prediction:és lastter. a'000 first'd a buy the percentred its shares on000 itted in a first ofÂ la la la Le la la\n",
            "Label:You knock over me, Prediction: est, be beenownked a, the but \" s a..ing, thes,vestman' Co. in......\n",
            "Label:  , Prediction: monde said, shotneked a.Kpt, s,, of the a.000. Hauke'.W la la la la la la la\n",
            "Label:Peter Gay plow a furrow, Prediction:ésading. world, the' s,, the, in,,ays. \"ther.ong.mp.ep. a ofviously'\n",
            "Label:London pump money, Prediction:ons, dansinée, theersschange-ls. the, was beenome a \"' ad for accordingmping a than $ice on a as was\n",
            "Label:  , Prediction: monde la,tained its theting jetscraft had000wardample.000 be use toough to theagever to toough to helpac the\n",
            "Label:  , Prediction: étéground worldill, de,, beat the worldated,il, said the' bemp the doat theound. on theet theaw\n",
            "Label:  , Prediction:onsel,diers,cked a car in me staras in had beenered the on thebanon on000 the otherdiers were killed civ\n",
            "Label:  , Prediction:onston,ter, a \"ner of but his a, wasd a., a n carill. thedee, \" l l l l\n",
            "Label:  , Prediction:ée, you worlder not a issue,e would do have' t been beenved. waydamental issue.ms.Â Le Le Le Le Le\n",
            "Label:  , Prediction:ons,night, the' beengeted a n Securityeronautics and Space Administration'eron, Center on the, stage Valley. where well as\n",
            "Label:  , Prediction:ons,' the spokeswal jud, theron, Ohio, it was not' t bey the \"endant. could have beend a un car\n",
            "Label:manufacturers pour money, Prediction: étér, ager than but' notkely to have $ than. the economytlefield aipp.. buting concern prospectgercedward meers\n",
            "Label:  , Prediction:onsons,an,000 most of peoplever ind byh,000ased by $85 millionred the.2,red Le la la la\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UCQtz4qk1Qc",
        "outputId": "b03c669c-356b-4bb9-c713-70c49550b801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 12.64858627319336,\n",
              " 'test_levenshtein_similarity': 0.06673972615206723,\n",
              " 'test_precision': 0.003943374633029806,\n",
              " 'test_recall': 0.003943374633029806,\n",
              " 'test_f1': 0.003943374633029806,\n",
              " 'test_runtime': 8.7081,\n",
              " 'test_samples_per_second': 19.981,\n",
              " 'test_steps_per_second': 0.345}"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels, metrics = trainer.predict(test_dataset=test_data_ger)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "u0ecJklmfibb",
        "outputId": "b4d785d2-ce0f-4e65-f416-c00462e395c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_token_ids = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# Step 2: Decode the predicted token IDs to text\n",
        "decoded_predictions = [tokenizer.decode(pred_seq, skip_special_tokens=True) for pred_seq in predicted_token_ids]\n",
        "decoded_labels = [tokenizer.decode(label_seq, skip_special_tokens=True) for label_seq in labels]\n",
        "# human comparison:\n",
        "for label,prediction in zip(decoded_labels,decoded_predictions):\n",
        "  print(f'Label:{label}, Prediction:{prediction}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEdTyH_GflpW",
        "outputId": "8484c3fd-0aae-47f1-cfee-353a9fd1eb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  , Prediction:éetaer Jahem,chlftigt,,ch inerorsri,lassenreoche,, ität.ürich\n",
            "Label:  , Prediction:ons,raurde i e d desumächst.ur,gangendenen dk inersmle unden.\n",
            "Label:  , Prediction:és,ll,,ilien,ben,ur, eil,it,ä,irglich, .Soliner.undse.te\n",
            "Label:sich Vorstellung erstrecken, Prediction:ée detver snischen Kachchritts.iren..terre orschung. e isets des der.\n",
            "Label:  , Prediction:onsgo faiten,achlfer,,iterel,.ückber,achhrung. ..b.. auatser\n",
            "Label:Fuß fassen , Prediction: hui     ',,,  enil,er endlichen, tenzeu..  ersten \"\n",
            "Label:  , Prediction:onsine,,ur, ersm e en Jah. undtraenerstteinen.achich.rscheinlich.. \n",
            "Label:Lücke schließen , Prediction: monde,ir es,wne,,,der fchg,der  - kt.tenach. der einer \n",
            "Label:  , Prediction:onsel,lteesetzichert,enn.m.ch,.lt. ir es ach, derm \"deren,\n",
            "Label:  , Prediction:onsgoen,,ach  \"idenifenen schon.osenbauer. iemir Ktin htum Jahillionnern s\n",
            "Label:  , Prediction:éeée.umtzt,el es,  egenes,ßnah,geen�ffonomische achmmausK \n",
            "Label:  , Prediction:ons,,,trst, n.jteal, intenzt ch inen. der USAlot.K Le Le \" \" \"\n",
            "Label:  , Prediction:ons,,ahhl,ch, ise,chentorsittag. ,.hr.2ut,el-did..mar\n",
            "Label:schüren Zweifel , Prediction:és.reinigung,ontigich,liemen, gangen Wönervati,ierung,kebenche,usit\n",
            "Label:  , Prediction:onslenden, osahnen, n�fflogenäntiones .fenht.achönen. ter.kehr\n",
            "Label:  , Prediction:ons,in   i Jahagedern,ten -Kitgliedschaft, iner treserung. fand\n",
            "Label:stoßen auf Kritik , Prediction:onselockeckte,,m,i e  en.tertützen.ositionsen Landesürgermeriegs. (.\n",
            "Label:  , Prediction:ée� nationalR, :w osex.�� t  ine             \n",
            "Label:unser Hemd teilen , Prediction:onsthen, au, \"fahhlung  irkterre er,. achheten,il..lte.\n",
            "Label:  , Prediction:ons, us, sstordneten,retenc, der ts.tenkun.inerenfalls. enten.\n",
            "Label:  , Prediction:és,beit,ite, \" sehre Kchen,chte - l  iren, iden,ektiert.\n",
            "Label:  , Prediction:éerace,lte,hn \",Kf.'er,irglich,.umhngenmenusstuelleelleniertte.T \"\n",
            "Label:  , Prediction: estience,ten.afer, ermhen, ageskei, dieenpolitische.iert. d diete ach   \n",
            "Label:Fahne Vertrauen erringen Vertrauen beschädigen, Prediction:onsgoastere,r,tene Jahtrauen,kgen. dassine mitirk inauf,eu. dass  n sechl\n",
            "Label:  , Prediction: été, late, ,,,operiyet \" \"  \"zial \"zverk \" \"ien \"ur,z vor,\n",
            "Label:nachzeichnen Unglück , Prediction:onsgo,tecttion.�  yth un�   ,'  ück,,un.,.   \n",
            "Label:Bus verpassen , Prediction:onsel,u,tengend,achht churst. edo iehungen.W \" \" \" \" \" \" \" \"\n",
            "Label:Beurteilung gewichten , Prediction:ons,Américcane,verachors,  kung, . begenenden Jah.. ken.gent.K\n",
            "Label:  , Prediction: ététeützung.den, \"isehe, achtag,achusang,t es ter anderem..bien.-\n",
            "Label:Ringen um Standard , Prediction:ons,angebach die -lte, ch,,enema..cherhalussungen.K Le \" \" \" \" \"\n",
            "Label:  , Prediction:ée detver mittgbungch die acherseneuelilosoph.attet.en \"tak.en. anverken.\n",
            "Label:  , Prediction:ons. iziellen,� . en thedingen,� aut.G Pacchonint  it .hrer \n",
            "Label:  , Prediction:ons,che Landesats, die ürkei,ind,liemer, \" is.��,2bt.de.   \n",
            "Label:  , Prediction:ons,urre,ch,chnet.i,us, ur es nte,, ze,geault. d lach\n",
            "Label:  , Prediction:és,rich,lete,tersannte, b, \"miumenorsgel,.� lmlos. undäb.�\n",
            "Label:  , Prediction:onsel,'ger,uen,tendings,ch inenchs ilichen,cht.K Le Le     Le \n",
            "Label:  , Prediction:ons',te,,.zent.hr als  leich..itg. Landesjahres.K la la la la la la\n",
            "Label:  , Prediction:ons.  ] ] ] ] ] ] rit ] utich es  \"en orsittl \"z      \n",
            "Label:  , Prediction:onsulé,,rek, en, \"m  \"esigen \"lageahl \" \"enück \" \"ordglicht \"en lang\n",
            "Label:  , Prediction:ons,ont, beong.5' inimlichültigmtschidung.iannt.ben. Le    \n",
            "Label:  , Prediction:onsthind,ine weiolden,ach au ,ur, ier-S \" \" \" \" \" \",,,...\n",
            "Label:  , Prediction:és.,elshden, enchen ra,gs, \"  \" \"en \" \"000 \".b \"ones \" \" ez\n",
            "Label:  , Prediction:onsner', nordner,ach tierwoch,lieeniffne. e angetionen Landesozres.azins.\n",
            "Label:Bogen machen , Prediction:onsgo,Unioncanat.000  e nbey-erne. dermisch-iert.chon. slte.gemonstranten\n",
            "Label:Schmuddel-Image abstreifen , Prediction:onsing,,,i e traindde, \"b..� achl ch  ite  ört. lich\n",
            "Label:  , Prediction:ons,0'z,.fckt, 12..onomieen. mb undder fenenen.. onned\n",
            "Label:  , Prediction:éeang, aff,genten,mterückbliche Regachrichtenung dieftraher,tionftra gzfen\n",
            "Label:Diskussion entfachen , Prediction:ée,eureuseder ür-  se aloginis undör,en. e ffentlichkeit.umhmend.m\n",
            "Label:  , Prediction:onsain,treisenatte,hnen e -000uten inerignete. \" \" \" \" \" \" \" \" \" \" \" \"\n",
            "Label:  , Prediction: hui�� , entlich,, chts lstommen,er  .h,chon .ls.i e\n",
            "Label:  , Prediction:ons,re t es ,ön, ch inach ds,ur, tigen,chetereff.urendet.\n",
            "Label:  , Prediction:és a,,agegen.mirglilich,,ch,wung. tei,K \" \" \" \" \" \" \" \" \"\n",
            "Label:  , Prediction:éetig, sont,,achteellente \" \"stenms \"ke deren \"iteunden \"langörzuückage desirtschaft\n",
            "Label:  , Prediction:ésmétiques,ction, lagcherung,trete,reör,ste,t esps-, dieencher, Jahrheittz.\n",
            "Label:  , Prediction:onsgoen sernt,do Jahüsste..m kell,,ch.  beitlosüche. inw\n",
            "Label:  , Prediction:és ommenden Jahachen desirgte, chichftskachrung, ,itet. die e beits\n",
            "Label:  , Prediction:ons.le ite,, langte,gen diees \"achnahtung.K           \n",
            "Label:  , Prediction:onsgoand,lde,örerte, e Kthur-Kander, derk, Norddesstaat..ordf Jah\n",
            "Label:  , Prediction:ée,irt,ach,,ühhlichke treSamzen Landes-TVino.� .tsch  cht  \n",
            "Label:  , Prediction:onses,,ir,, ,,en i nachze,,  in d    ühere   \n",
            "Label:  , Prediction:ons,.mb,i den achdernöchen,ück-versität.. ent,et.iits..ich\n",
            "Label:  , Prediction:onsissadeung,den, eaben des rieission ingesondere.gischen Regtitionen. swei ispiel des\n",
            "Label:  , Prediction:onsel', seiben,utschen Strechtungverager, s ge ebiet. teen,en.g\n",
            "Label:  , Prediction:onsthen,inirtig,,enum el des der n,Kerbitzung.umammen.benallenten.com un\n",
            "Label:  , Prediction:ons',,en \"unden. iner, chine. ise, e.getzen.önte.K Le Le Le Le\n",
            "Label:  , Prediction:ons,iner ohen \"ienteung,tenenön.mohtteige \" Regwirung.inerenfalls.ken.\n",
            "Label:  , Prediction:ée deeng,Leum, Berlinussedwestrol,,,,, ähe,T der,ez Le. dasach,ner,\n",
            "Label:Laufbahn ruinieren Schatten auf Karriere werfen, Prediction:onsthiren,örglichkeit,,ückachferungrempfung,.en Verene.indffen. sagenn es\n",
            "Label:  , Prediction:onsoilerä,'sst,,ch nichti Jahitere,..gen.S la la la la la la la la la Le la\n",
            "Label:  , Prediction:ons,,rerler,,cieristen usgnen..omberg \" ench \".mittlungen \"  \" \"l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYyrT8vofooR",
        "outputId": "e8d425e9-eaf9-432c-8130-02e3851bde2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 1.691941738128662,\n",
              " 'test_levenshtein_similarity': 0.26926719367565816,\n",
              " 'test_precision': 0.2642857142857143,\n",
              " 'test_recall': 0.2642857142857143,\n",
              " 'test_f1': 0.2642857142857143,\n",
              " 'test_runtime': 3.1693,\n",
              " 'test_samples_per_second': 22.087,\n",
              " 'test_steps_per_second': 0.631}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MrLDOzljkqM9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}